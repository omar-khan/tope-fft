//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Sat Apr  7 09:27:48 2012 (1333783668)
// Driver 295.41
//

.version 3.0
.target sm_13, texmode_independent
.address_size 32

.const .align 8 .b8 __internal_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.entry twiddles(
	.param .u32 .ptr .global .align 16 twiddles_param_0,
	.param .u32 twiddles_param_1
)
{
	.local .align 8 .b8 	__local_depot0[40];
	.reg .b32 	%SP;
	.reg .f64 	%fd<178>;
	.reg .pred 	%p<37>;
	.reg .s32 	%r<128>;
	.reg .s64 	%rl<167>;


	mov.u32 	%SP, __local_depot0;
	ld.param.u32 	%r41, [twiddles_param_1];
	// inline asm
	mov.u32 	%r37, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r38, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r39, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r40, %tid.x;
	// inline asm
	add.s32 	%r42, %r40, %r37;
	mad.lo.s32 	%r2, %r39, %r38, %r42;
	cvt.rn.f64.s32 	%fd22, %r2;
	mul.f64 	%fd23, %fd22, 0d401921FB54442D18;
	cvt.rn.f64.s32 	%fd24, %r41;
	div.rn.f64 	%fd1, %fd23, %fd24;
	setp.eq.f64 	%p1, %fd1, 0d7FF0000000000000;
	setp.eq.f64 	%p2, %fd1, 0dFFF0000000000000;
	or.pred  	%p3, %p1, %p2;
	add.u32 	%r3, %SP, 0;
	@%p3 bra 	BB0_23;

	// inline asm
	abs.f64 	%fd25, %fd1;
	// inline asm
	setp.gt.f64 	%p4, %fd25, 0d41E0000000000000;
	@%p4 bra 	BB0_3;

	mov.f64 	%fd40, 0d3FE45F306DC9C883;
	mul.rn.f64 	%fd27, %fd1, %fd40;
	// inline asm
	cvt.rni.s32.f64 	%r43, %fd27;
	// inline asm
	cvt.rn.f64.s32 	%fd41, %r43;
	neg.f64 	%fd37, %fd41;
	mov.f64 	%fd30, 0d3FF921FB54442D18;
	// inline asm
	fma.rn.f64 	%fd28, %fd37, %fd30, %fd1;
	// inline asm
	mov.f64 	%fd34, 0d3C91A62633145C00;
	// inline asm
	fma.rn.f64 	%fd32, %fd37, %fd34, %fd28;
	// inline asm
	mov.f64 	%fd38, 0d397B839A252049C0;
	// inline asm
	fma.rn.f64 	%fd36, %fd37, %fd38, %fd32;
	// inline asm
	mov.u32 	%r124, %r43;
	mov.f64 	%fd172, %fd36;
	bra.uni 	BB0_19;

BB0_3:
	mov.b64 	 %rl1, %fd1;
	and.b64  	%rl150, %rl1, -9223372036854775808;
	shr.u64 	%rl3, %rl1, 52;
	and.b64  	%rl65, %rl3, 2047;
	add.s64 	%rl66, %rl65, 4294966272;
	cvt.u32.u64 	%r5, %rl66;
	shl.b64 	%rl67, %rl1, 11;
	or.b64  	%rl4, %rl67, -9223372036854775808;
	shr.u32 	%r47, %r5, 6;
	mov.u32 	%r48, 16;
	sub.s32 	%r6, %r48, %r47;
	mov.u32 	%r49, 15;
	sub.s32 	%r122, %r49, %r47;
	mov.u32 	%r50, 19;
	sub.s32 	%r8, %r50, %r47;
	mov.u32 	%r45, 18;
	// inline asm
	min.s32 	%r44, %r45, %r8;
	// inline asm
	setp.lt.s32 	%p5, %r122, %r44;
	@%p5 bra 	BB0_5;

	mov.u64 	%rl147, 0;
	bra.uni 	BB0_7;

BB0_5:
	mov.u32 	%r51, 1;
	sub.s32 	%r9, %r51, %r6;
	mov.u64 	%rl147, 0;

BB0_6:
	.pragma "nounroll";
	shl.b32 	%r55, %r122, 3;
	mov.u32 	%r56, __internal_i2opi_d;
	add.s32 	%r57, %r56, %r55;
	ld.const.u64 	%rl71, [%r57];
	mul.lo.s64 	%rl73, %rl71, %rl4;
	// inline asm
	mul.hi.u64 	%rl70, %rl71, %rl4;
	// inline asm
	mad.lo.s64 	%rl74, %rl71, %rl4, %rl147;
	setp.lt.u64 	%p6, %rl74, %rl73;
	selp.u64 	%rl75, 1, 0, %p6;
	add.s64 	%rl147, %rl75, %rl70;
	add.s32 	%r58, %r9, %r122;
	shl.b32 	%r59, %r58, 3;
	add.s32 	%r61, %r3, %r59;
	st.local.u64 	[%r61], %rl74;
	// inline asm
	min.s32 	%r52, %r45, %r8;
	// inline asm
	add.s32 	%r122, %r122, 1;
	setp.lt.s32 	%p7, %r122, %r52;
	@%p7 bra 	BB0_6;

BB0_7:
	mov.u32 	%r62, 1;
	sub.s32 	%r63, %r62, %r6;
	add.s32 	%r64, %r63, %r122;
	shl.b32 	%r65, %r64, 3;
	add.s32 	%r67, %r3, %r65;
	st.local.u64 	[%r67], %rl147;
	ld.local.u64 	%rl148, [%r3+24];
	ld.local.u64 	%rl149, [%r3+16];
	and.b32  	%r68, %r5, 63;
	setp.eq.s32 	%p8, %r68, 0;
	@%p8 bra 	BB0_9;

	and.b64  	%rl76, %rl3, 63;
	cvt.u32.u64 	%r69, %rl76;
	shl.b64 	%rl77, %rl148, %r69;
	neg.s32 	%r70, %r5;
	and.b32  	%r71, %r70, 63;
	shr.u64 	%rl78, %rl149, %r71;
	or.b64  	%rl148, %rl78, %rl77;
	shl.b64 	%rl79, %rl149, %r69;
	ld.local.u64 	%rl80, [%r3+8];
	shr.u64 	%rl81, %rl80, %r71;
	or.b64  	%rl149, %rl81, %rl79;

BB0_9:
	shr.u64 	%rl82, %rl148, 62;
	cvt.u32.u64 	%r72, %rl82;
	shr.u64 	%rl83, %rl149, 62;
	shl.b64 	%rl84, %rl148, 2;
	or.b64  	%rl154, %rl83, %rl84;
	shl.b64 	%rl15, %rl149, 2;
	setp.ne.s64 	%p9, %rl15, 0;
	selp.u64 	%rl85, 1, 0, %p9;
	or.b64  	%rl86, %rl85, %rl154;
	setp.gt.u64 	%p10, %rl86, -9223372036854775808;
	selp.u32 	%r73, 1, 0, %p10;
	add.s32 	%r74, %r73, %r72;
	neg.s32 	%r75, %r74;
	setp.lt.s64 	%p11, %rl1, 0;
	selp.b32 	%r124, %r75, %r74, %p11;
	@%p10 bra 	BB0_11;

	mov.u64 	%rl153, %rl15;
	bra.uni 	BB0_12;

BB0_11:
	not.b64 	%rl87, %rl154;
	neg.s64 	%rl16, %rl15;
	setp.eq.s64 	%p12, %rl15, 0;
	selp.u64 	%rl88, 1, 0, %p12;
	add.s64 	%rl154, %rl88, %rl87;
	xor.b64  	%rl150, %rl150, -9223372036854775808;
	mov.u64 	%rl153, %rl16;

BB0_12:
	mov.u64 	%rl152, %rl153;
	setp.gt.s64 	%p13, %rl154, 0;
	@%p13 bra 	BB0_14;

	mov.u32 	%r123, 0;
	bra.uni 	BB0_16;

BB0_14:
	mov.u32 	%r123, 0;

BB0_15:
	shr.u64 	%rl89, %rl152, 63;
	shl.b64 	%rl90, %rl154, 1;
	or.b64  	%rl154, %rl89, %rl90;
	shl.b64 	%rl152, %rl152, 1;
	add.s32 	%r123, %r123, -1;
	setp.gt.s64 	%p14, %rl154, 0;
	@%p14 bra 	BB0_15;

BB0_16:
	mul.lo.s64 	%rl156, %rl154, -3958705157555305931;
	mov.u64 	%rl93, -3958705157555305931;
	// inline asm
	mul.hi.u64 	%rl91, %rl154, %rl93;
	// inline asm
	setp.gt.s64 	%p15, %rl91, 0;
	mov.u64 	%rl155, %rl91;
	@%p15 bra 	BB0_17;
	bra.uni 	BB0_18;

BB0_17:
	shl.b64 	%rl94, %rl91, 1;
	shr.u64 	%rl95, %rl156, 63;
	or.b64  	%rl155, %rl94, %rl95;
	mul.lo.s64 	%rl156, %rl154, -7917410315110611862;
	add.s32 	%r123, %r123, -1;

BB0_18:
	setp.ne.s64 	%p16, %rl156, 0;
	selp.u64 	%rl96, 1, 0, %p16;
	add.s64 	%rl97, %rl96, %rl155;
	add.s32 	%r78, %r123, 1022;
	cvt.u64.u32 	%rl98, %r78;
	shl.b64 	%rl99, %rl98, 52;
	shr.u64 	%rl100, %rl97, 11;
	shr.u64 	%rl101, %rl97, 10;
	and.b64  	%rl102, %rl101, 1;
	add.s64 	%rl103, %rl99, %rl100;
	add.s64 	%rl104, %rl103, %rl102;
	or.b64  	%rl105, %rl104, %rl150;
	mov.b64 	 %fd172, %rl105;

BB0_19:
	add.s32 	%r20, %r124, 1;
	and.b32  	%r79, %r20, 1;
	setp.eq.s32 	%p17, %r79, 0;
	mul.rn.f64 	%fd5, %fd172, %fd172;
	@%p17 bra 	BB0_21;

	mov.f64 	%fd43, 0dBDA8FF8D5A8F03DB;
	mov.f64 	%fd45, 0d3E21EEA7D67FAD92;
	// inline asm
	fma.rn.f64 	%fd42, %fd43, %fd5, %fd45;
	// inline asm
	mov.f64 	%fd49, 0dBE927E4F8E26B8E3;
	// inline asm
	fma.rn.f64 	%fd46, %fd42, %fd5, %fd49;
	// inline asm
	mov.f64 	%fd53, 0d3EFA01A019DDEC33;
	// inline asm
	fma.rn.f64 	%fd50, %fd46, %fd5, %fd53;
	// inline asm
	mov.f64 	%fd57, 0dBF56C16C16C15D69;
	// inline asm
	fma.rn.f64 	%fd54, %fd50, %fd5, %fd57;
	// inline asm
	mov.f64 	%fd61, 0d3FA5555555555551;
	// inline asm
	fma.rn.f64 	%fd58, %fd54, %fd5, %fd61;
	// inline asm
	mov.f64 	%fd65, 0dBFE0000000000000;
	// inline asm
	fma.rn.f64 	%fd62, %fd58, %fd5, %fd65;
	// inline asm
	mov.f64 	%fd69, 0d3FF0000000000000;
	// inline asm
	fma.rn.f64 	%fd66, %fd62, %fd5, %fd69;
	// inline asm
	mov.f64 	%fd173, %fd66;
	bra.uni 	BB0_22;

BB0_21:
	mov.f64 	%fd71, 0d3DE5D8FD1FCF0EC1;
	mov.f64 	%fd73, 0dBE5AE5E5A9291691;
	// inline asm
	fma.rn.f64 	%fd70, %fd71, %fd5, %fd73;
	// inline asm
	mov.f64 	%fd77, 0d3EC71DE3567D4896;
	// inline asm
	fma.rn.f64 	%fd74, %fd70, %fd5, %fd77;
	// inline asm
	mov.f64 	%fd81, 0dBF2A01A019BFDF03;
	// inline asm
	fma.rn.f64 	%fd78, %fd74, %fd5, %fd81;
	// inline asm
	mov.f64 	%fd85, 0d3F8111111110F7D0;
	// inline asm
	fma.rn.f64 	%fd82, %fd78, %fd5, %fd85;
	// inline asm
	mov.f64 	%fd89, 0dBFC5555555555548;
	// inline asm
	fma.rn.f64 	%fd86, %fd82, %fd5, %fd89;
	// inline asm
	mul.rn.f64 	%fd91, %fd86, %fd5;
	// inline asm
	fma.rn.f64 	%fd90, %fd91, %fd172, %fd172;
	// inline asm
	mov.f64 	%fd173, %fd90;

BB0_22:
	and.b32  	%r80, %r20, 2;
	setp.eq.s32 	%p18, %r80, 0;
	neg.f64 	%fd94, %fd173;
	selp.f64 	%fd174, %fd173, %fd94, %p18;
	bra.uni 	BB0_24;

BB0_23:
	mov.f64 	%fd174, 0dFFF8000000000000;

BB0_24:
	setp.eq.f64 	%p19, %fd1, 0d0000000000000000;
	or.pred  	%p20, %p2, %p19;
	or.pred  	%p21, %p1, %p20;
	@%p21 bra 	BB0_47;

	// inline asm
	abs.f64 	%fd96, %fd1;
	// inline asm
	setp.gt.f64 	%p22, %fd96, 0d41E0000000000000;
	@%p22 bra 	BB0_27;

	mov.f64 	%fd111, 0d3FE45F306DC9C883;
	mul.rn.f64 	%fd98, %fd1, %fd111;
	// inline asm
	cvt.rni.s32.f64 	%r81, %fd98;
	// inline asm
	cvt.rn.f64.s32 	%fd112, %r81;
	neg.f64 	%fd108, %fd112;
	mov.f64 	%fd101, 0d3FF921FB54442D18;
	// inline asm
	fma.rn.f64 	%fd99, %fd108, %fd101, %fd1;
	// inline asm
	mov.f64 	%fd105, 0d3C91A62633145C00;
	// inline asm
	fma.rn.f64 	%fd103, %fd108, %fd105, %fd99;
	// inline asm
	mov.f64 	%fd109, 0d397B839A252049C0;
	// inline asm
	fma.rn.f64 	%fd107, %fd108, %fd109, %fd103;
	// inline asm
	mov.u32 	%r127, %r81;
	mov.f64 	%fd175, %fd107;
	bra.uni 	BB0_43;

BB0_27:
	mov.b64 	 %rl33, %fd1;
	and.b64  	%rl160, %rl33, -9223372036854775808;
	shr.u64 	%rl35, %rl33, 52;
	and.b64  	%rl106, %rl35, 2047;
	add.s64 	%rl107, %rl106, 4294966272;
	cvt.u32.u64 	%r22, %rl107;
	shl.b64 	%rl108, %rl33, 11;
	or.b64  	%rl36, %rl108, -9223372036854775808;
	shr.u32 	%r85, %r22, 6;
	mov.u32 	%r86, 16;
	sub.s32 	%r23, %r86, %r85;
	mov.u32 	%r87, 15;
	sub.s32 	%r125, %r87, %r85;
	mov.u32 	%r88, 19;
	sub.s32 	%r25, %r88, %r85;
	mov.u32 	%r83, 18;
	// inline asm
	min.s32 	%r82, %r83, %r25;
	// inline asm
	setp.lt.s32 	%p23, %r125, %r82;
	@%p23 bra 	BB0_29;

	mov.u64 	%rl157, 0;
	bra.uni 	BB0_31;

BB0_29:
	mov.u32 	%r89, 1;
	sub.s32 	%r26, %r89, %r23;
	mov.u64 	%rl157, 0;

BB0_30:
	.pragma "nounroll";
	shl.b32 	%r93, %r125, 3;
	mov.u32 	%r94, __internal_i2opi_d;
	add.s32 	%r95, %r94, %r93;
	ld.const.u64 	%rl112, [%r95];
	mul.lo.s64 	%rl114, %rl112, %rl36;
	// inline asm
	mul.hi.u64 	%rl111, %rl112, %rl36;
	// inline asm
	mad.lo.s64 	%rl115, %rl112, %rl36, %rl157;
	setp.lt.u64 	%p24, %rl115, %rl114;
	selp.u64 	%rl116, 1, 0, %p24;
	add.s64 	%rl157, %rl116, %rl111;
	add.s32 	%r96, %r26, %r125;
	shl.b32 	%r97, %r96, 3;
	add.s32 	%r99, %r3, %r97;
	st.local.u64 	[%r99], %rl115;
	// inline asm
	min.s32 	%r90, %r83, %r25;
	// inline asm
	add.s32 	%r125, %r125, 1;
	setp.lt.s32 	%p25, %r125, %r90;
	@%p25 bra 	BB0_30;

BB0_31:
	mov.u32 	%r100, 1;
	sub.s32 	%r101, %r100, %r23;
	add.s32 	%r102, %r101, %r125;
	shl.b32 	%r103, %r102, 3;
	add.s32 	%r105, %r3, %r103;
	st.local.u64 	[%r105], %rl157;
	ld.local.u64 	%rl158, [%r3+24];
	ld.local.u64 	%rl159, [%r3+16];
	and.b32  	%r106, %r22, 63;
	setp.eq.s32 	%p26, %r106, 0;
	@%p26 bra 	BB0_33;

	and.b64  	%rl117, %rl35, 63;
	cvt.u32.u64 	%r107, %rl117;
	shl.b64 	%rl118, %rl158, %r107;
	neg.s32 	%r108, %r22;
	and.b32  	%r109, %r108, 63;
	shr.u64 	%rl119, %rl159, %r109;
	or.b64  	%rl158, %rl119, %rl118;
	shl.b64 	%rl120, %rl159, %r107;
	ld.local.u64 	%rl121, [%r3+8];
	shr.u64 	%rl122, %rl121, %r109;
	or.b64  	%rl159, %rl122, %rl120;

BB0_33:
	shr.u64 	%rl123, %rl158, 62;
	cvt.u32.u64 	%r110, %rl123;
	shr.u64 	%rl124, %rl159, 62;
	shl.b64 	%rl125, %rl158, 2;
	or.b64  	%rl164, %rl124, %rl125;
	shl.b64 	%rl47, %rl159, 2;
	setp.ne.s64 	%p27, %rl47, 0;
	selp.u64 	%rl126, 1, 0, %p27;
	or.b64  	%rl127, %rl126, %rl164;
	setp.gt.u64 	%p28, %rl127, -9223372036854775808;
	selp.u32 	%r111, 1, 0, %p28;
	add.s32 	%r112, %r111, %r110;
	neg.s32 	%r113, %r112;
	setp.lt.s64 	%p29, %rl33, 0;
	selp.b32 	%r127, %r113, %r112, %p29;
	@%p28 bra 	BB0_35;

	mov.u64 	%rl163, %rl47;
	bra.uni 	BB0_36;

BB0_35:
	not.b64 	%rl128, %rl164;
	neg.s64 	%rl48, %rl47;
	setp.eq.s64 	%p30, %rl47, 0;
	selp.u64 	%rl129, 1, 0, %p30;
	add.s64 	%rl164, %rl129, %rl128;
	xor.b64  	%rl160, %rl160, -9223372036854775808;
	mov.u64 	%rl163, %rl48;

BB0_36:
	mov.u64 	%rl162, %rl163;
	setp.gt.s64 	%p31, %rl164, 0;
	@%p31 bra 	BB0_38;

	mov.u32 	%r126, 0;
	bra.uni 	BB0_40;

BB0_38:
	mov.u32 	%r126, 0;

BB0_39:
	shr.u64 	%rl130, %rl162, 63;
	shl.b64 	%rl131, %rl164, 1;
	or.b64  	%rl164, %rl130, %rl131;
	shl.b64 	%rl162, %rl162, 1;
	add.s32 	%r126, %r126, -1;
	setp.gt.s64 	%p32, %rl164, 0;
	@%p32 bra 	BB0_39;

BB0_40:
	mul.lo.s64 	%rl166, %rl164, -3958705157555305931;
	mov.u64 	%rl134, -3958705157555305931;
	// inline asm
	mul.hi.u64 	%rl132, %rl164, %rl134;
	// inline asm
	setp.gt.s64 	%p33, %rl132, 0;
	mov.u64 	%rl165, %rl132;
	@%p33 bra 	BB0_41;
	bra.uni 	BB0_42;

BB0_41:
	shl.b64 	%rl135, %rl132, 1;
	shr.u64 	%rl136, %rl166, 63;
	or.b64  	%rl165, %rl135, %rl136;
	mul.lo.s64 	%rl166, %rl164, -7917410315110611862;
	add.s32 	%r126, %r126, -1;

BB0_42:
	setp.ne.s64 	%p34, %rl166, 0;
	selp.u64 	%rl137, 1, 0, %p34;
	add.s64 	%rl138, %rl137, %rl165;
	add.s32 	%r116, %r126, 1022;
	cvt.u64.u32 	%rl139, %r116;
	shl.b64 	%rl140, %rl139, 52;
	shr.u64 	%rl141, %rl138, 11;
	shr.u64 	%rl142, %rl138, 10;
	and.b64  	%rl143, %rl142, 1;
	add.s64 	%rl144, %rl140, %rl141;
	add.s64 	%rl145, %rl144, %rl143;
	or.b64  	%rl146, %rl145, %rl160;
	mov.b64 	 %fd175, %rl146;

BB0_43:
	and.b32  	%r117, %r127, 1;
	setp.eq.s32 	%p35, %r117, 0;
	mul.rn.f64 	%fd15, %fd175, %fd175;
	@%p35 bra 	BB0_45;

	mov.f64 	%fd114, 0dBDA8FF8D5A8F03DB;
	mov.f64 	%fd116, 0d3E21EEA7D67FAD92;
	// inline asm
	fma.rn.f64 	%fd113, %fd114, %fd15, %fd116;
	// inline asm
	mov.f64 	%fd120, 0dBE927E4F8E26B8E3;
	// inline asm
	fma.rn.f64 	%fd117, %fd113, %fd15, %fd120;
	// inline asm
	mov.f64 	%fd124, 0d3EFA01A019DDEC33;
	// inline asm
	fma.rn.f64 	%fd121, %fd117, %fd15, %fd124;
	// inline asm
	mov.f64 	%fd128, 0dBF56C16C16C15D69;
	// inline asm
	fma.rn.f64 	%fd125, %fd121, %fd15, %fd128;
	// inline asm
	mov.f64 	%fd132, 0d3FA5555555555551;
	// inline asm
	fma.rn.f64 	%fd129, %fd125, %fd15, %fd132;
	// inline asm
	mov.f64 	%fd136, 0dBFE0000000000000;
	// inline asm
	fma.rn.f64 	%fd133, %fd129, %fd15, %fd136;
	// inline asm
	mov.f64 	%fd140, 0d3FF0000000000000;
	// inline asm
	fma.rn.f64 	%fd137, %fd133, %fd15, %fd140;
	// inline asm
	mov.f64 	%fd176, %fd137;
	bra.uni 	BB0_46;

BB0_45:
	mov.f64 	%fd142, 0d3DE5D8FD1FCF0EC1;
	mov.f64 	%fd144, 0dBE5AE5E5A9291691;
	// inline asm
	fma.rn.f64 	%fd141, %fd142, %fd15, %fd144;
	// inline asm
	mov.f64 	%fd148, 0d3EC71DE3567D4896;
	// inline asm
	fma.rn.f64 	%fd145, %fd141, %fd15, %fd148;
	// inline asm
	mov.f64 	%fd152, 0dBF2A01A019BFDF03;
	// inline asm
	fma.rn.f64 	%fd149, %fd145, %fd15, %fd152;
	// inline asm
	mov.f64 	%fd156, 0d3F8111111110F7D0;
	// inline asm
	fma.rn.f64 	%fd153, %fd149, %fd15, %fd156;
	// inline asm
	mov.f64 	%fd160, 0dBFC5555555555548;
	// inline asm
	fma.rn.f64 	%fd157, %fd153, %fd15, %fd160;
	// inline asm
	mul.rn.f64 	%fd162, %fd157, %fd15;
	// inline asm
	fma.rn.f64 	%fd161, %fd162, %fd175, %fd175;
	// inline asm
	mov.f64 	%fd176, %fd161;

BB0_46:
	and.b32  	%r118, %r127, 2;
	setp.eq.s32 	%p36, %r118, 0;
	neg.f64 	%fd165, %fd176;
	selp.f64 	%fd177, %fd176, %fd165, %p36;
	bra.uni 	BB0_48;

BB0_47:
	mov.f64 	%fd166, 0d0000000000000000;
	mul.rn.f64 	%fd177, %fd1, %fd166;

BB0_48:
	neg.f64 	%fd167, %fd177;
	shl.b32 	%r119, %r2, 4;
	ld.param.u32 	%r121, [twiddles_param_0];
	add.s32 	%r120, %r121, %r119;
	st.global.v2.f64 	[%r120], {%fd174, %fd167};
	ret;
}

.entry DIT8C2C(
	.param .u32 .ptr .global .align 8 DIT8C2C_param_0,
	.param .u32 .ptr .global .align 16 DIT8C2C_param_1,
	.param .u32 DIT8C2C_param_2,
	.param .u32 DIT8C2C_param_3,
	.param .u32 DIT8C2C_param_4,
	.param .u32 DIT8C2C_param_5,
	.param .u32 DIT8C2C_param_6
)
{
	.reg .f32 	%f<293>;
	.reg .f64 	%fd<846>;
	.reg .pred 	%p<68>;
	.reg .s32 	%r<195>;


	ld.param.u32 	%r69, [DIT8C2C_param_4];
	// inline asm
	mov.u32 	%r61, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r62, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r63, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r64, %tid.x;
	// inline asm
	add.s32 	%r70, %r64, %r61;
	mad.lo.s32 	%r7, %r63, %r62, %r70;
	// inline asm
	mov.u32 	%r65, %envreg4;
	// inline asm
	// inline asm
	mov.u32 	%r66, %ntid.y;
	// inline asm
	// inline asm
	mov.u32 	%r67, %ctaid.y;
	// inline asm
	// inline asm
	mov.u32 	%r68, %tid.y;
	// inline asm
	add.s32 	%r71, %r68, %r65;
	mad.lo.s32 	%r8, %r67, %r66, %r71;
	shr.s32 	%r72, %r69, 31;
	shr.u32 	%r73, %r72, 30;
	add.s32 	%r74, %r69, %r73;
	shr.s32 	%r9, %r74, 2;
	and.b32  	%r75, %r74, -4;
	sub.s32 	%r10, %r69, %r75;
	setp.gt.s32 	%p9, %r69, 3;
	@%p9 bra 	BB1_2;

	mov.f32 	%f284, 0f3F800000;
	bra.uni 	BB1_23;

BB1_2:
	mov.f32 	%f1, 0f40800000;
	mov.pred 	%p3, 0;
	mov.f32 	%f47, 0f41000000;
	add.f32 	%f2, %f47, 0f40800000;
	mov.f32 	%f3, 0f7F800000;
	mov.f32 	%f4, 0f00000000;
	mov.f32 	%f5, 0f37000000;
	mov.u32 	%r186, 1;
	mov.u32 	%r185, 0;

BB1_3:
	// inline asm
	abs.f32 	%f48, %f47;
	// inline asm
	selp.f32 	%f7, 0f3F800000, %f2, %p3;
	or.pred  	%p10, %p3, %p3;
	@%p10 bra 	BB1_20;

	mov.f32 	%f54, 0f3F000000;
	mul.rn.f32 	%f51, %f54, %f1;
	// inline asm
	cvt.rmi.f32.f32 	%f50, %f51;
	// inline asm
	mov.f32 	%f55, 0f40000000;
	mul.rn.f32 	%f56, %f55, %f50;
	sub.f32 	%f57, %f1, %f56;
	setp.eq.f32 	%p11, %f57, 0f3F800000;
	// inline asm
	cvt.rzi.f32.f32 	%f52, %f1;
	// inline asm
	setp.eq.f32 	%p12, %f1, %f52;
	and.pred  	%p4, %p11, %p12;
	setp.eq.f32 	%p13, %f48, 0f00000000;
	@%p13 bra 	BB1_17;

	// inline asm
	abs.f32 	%f58, %f47;
	// inline asm
	mov.b32 	 %r13, %f58;
	shr.u32 	%r78, %r13, 23;
	and.b32  	%r79, %r78, 255;
	add.s32 	%r187, %r79, -127;
	setp.eq.s32 	%p14, %r79, 0;
	mov.f32 	%f280, %f58;
	@%p14 bra 	BB1_6;
	bra.uni 	BB1_7;

BB1_6:
	and.b32  	%r80, %r13, -2139095041;
	or.b32  	%r81, %r80, 1065353216;
	mov.b32 	 %f60, %r81;
	add.f32 	%f61, %f60, 0fBF800000;
	mov.b32 	 %r82, %f61;
	shr.u32 	%r83, %r82, 23;
	and.b32  	%r84, %r83, 255;
	add.s32 	%r187, %r84, -253;
	and.b32  	%r85, %r82, -2139095041;
	or.b32  	%r86, %r85, 1065353216;
	mov.b32 	 %f280, %r86;

BB1_7:
	mov.b32 	 %r87, %f280;
	and.b32  	%r88, %r87, -2139095041;
	or.b32  	%r89, %r88, 1065353216;
	mov.b32 	 %f281, %r89;
	setp.gt.f32 	%p15, %f281, 0f3FB504F3;
	@%p15 bra 	BB1_8;
	bra.uni 	BB1_9;

BB1_8:
	mul.rn.f32 	%f281, %f281, %f54;
	add.s32 	%r187, %r187, 1;

BB1_9:
	add.f32 	%f71, %f281, 0f3F800000;
	rcp.approx.f32 	%f65, %f71;
	add.f32 	%f64, %f281, 0fBF800000;
	// inline asm
	mul.rz.f32 	%f63, %f64, %f65;
	// inline asm
	mul.rn.f32 	%f73, %f55, %f63;
	mul.rn.f32 	%f74, %f73, %f73;
	mov.f32 	%f75, 0f3B18F0FE;
	mul.rn.f32 	%f76, %f75, %f74;
	add.f32 	%f77, %f76, 0f3C4CAF63;
	mul.rn.f32 	%f78, %f77, %f74;
	add.f32 	%f79, %f78, 0f3DAAAABD;
	mul.rn.f32 	%f80, %f79, %f74;
	mul.rn.f32 	%f68, %f80, %f73;
	mov.b32 	 %r90, %f73;
	and.b32  	%r91, %r90, -4096;
	mov.b32 	 %f81, %r91;
	mov.b32 	 %r92, %f64;
	and.b32  	%r93, %r92, -4096;
	mov.b32 	 %f82, %r93;
	sub.f32 	%f83, %f64, %f81;
	mul.rn.f32 	%f84, %f55, %f83;
	sub.f32 	%f85, %f64, %f82;
	mul.rn.f32 	%f86, %f81, %f82;
	sub.f32 	%f87, %f84, %f86;
	mul.rn.f32 	%f88, %f81, %f85;
	sub.f32 	%f89, %f87, %f88;
	mul.rn.f32 	%f90, %f65, %f89;
	add.f32 	%f91, %f81, %f90;
	sub.f32 	%f92, %f91, %f81;
	sub.f32 	%f93, %f90, %f92;
	add.f32 	%f94, %f91, %f68;
	sub.f32 	%f67, %f91, %f94;
	// inline asm
	add.rz.f32 	%f66, %f67, %f68;
	// inline asm
	add.f32 	%f95, %f66, %f93;
	add.f32 	%f96, %f94, %f95;
	sub.f32 	%f97, %f94, %f96;
	add.f32 	%f98, %f97, %f95;
	cvt.rn.f32.s32 	%f99, %r187;
	mov.f32 	%f100, 0f3F317200;
	mul.rn.f32 	%f101, %f99, %f100;
	mov.f32 	%f102, 0f35BFBE8E;
	mul.rn.f32 	%f103, %f99, %f102;
	add.f32 	%f104, %f101, %f96;
	sub.f32 	%f105, %f101, %f104;
	add.f32 	%f106, %f105, %f96;
	add.f32 	%f107, %f106, %f98;
	add.f32 	%f108, %f107, %f103;
	add.f32 	%f14, %f104, %f108;
	sub.f32 	%f109, %f104, %f14;
	add.f32 	%f15, %f109, %f108;
	// inline asm
	abs.f32 	%f69, %f1;
	// inline asm
	setp.gt.f32 	%p16, %f69, 0f77F684DF;
	@%p16 bra 	BB1_11;

	mov.f32 	%f282, %f1;
	bra.uni 	BB1_12;

BB1_11:
	mov.f32 	%f110, 0f39000000;
	mul.rn.f32 	%f16, %f1, %f110;
	mov.f32 	%f282, %f16;

BB1_12:
	mov.f32 	%f17, %f282;
	mov.f32 	%f111, 0f45800800;
	mul.rn.f32 	%f112, %f14, %f111;
	sub.f32 	%f113, %f14, %f112;
	add.f32 	%f114, %f113, %f112;
	sub.f32 	%f115, %f14, %f114;
	mul.rn.f32 	%f116, %f17, %f111;
	sub.f32 	%f117, %f17, %f116;
	add.f32 	%f118, %f117, %f116;
	sub.f32 	%f119, %f17, %f118;
	mul.rn.f32 	%f120, %f114, %f118;
	mul.rn.f32 	%f121, %f14, %f17;
	sub.f32 	%f122, %f120, %f121;
	mul.rn.f32 	%f123, %f114, %f119;
	add.f32 	%f124, %f122, %f123;
	mul.rn.f32 	%f125, %f115, %f118;
	add.f32 	%f126, %f124, %f125;
	mul.rn.f32 	%f127, %f115, %f119;
	add.f32 	%f128, %f126, %f127;
	mul.rn.f32 	%f129, %f15, %f17;
	add.f32 	%f130, %f129, %f128;
	add.f32 	%f131, %f121, %f130;
	sub.f32 	%f132, %f121, %f131;
	add.f32 	%f18, %f132, %f130;
	mov.f32 	%f291, %f18;
	mov.f32 	%f292, %f131;
	mov.b32 	 %r19, %f131;
	setp.eq.s32 	%p17, %r19, 1118925336;
	@%p17 bra 	BB1_13;
	bra.uni 	BB1_14;

BB1_13:
	add.s32 	%r94, %r19, -1;
	mov.b32 	 %f133, %r94;
	add.f32 	%f134, %f18, %f5;
	mov.f32 	%f291, %f134;
	mov.f32 	%f292, %f133;

BB1_14:
	mov.f32 	%f142, 0f3FB8AA3B;
	mul.rn.f32 	%f136, %f292, %f142;
	// inline asm
	cvt.rzi.f32.f32 	%f135, %f136;
	// inline asm
	mul.rn.f32 	%f144, %f135, %f100;
	sub.f32 	%f145, %f292, %f144;
	mul.rn.f32 	%f147, %f135, %f102;
	sub.f32 	%f148, %f145, %f147;
	mul.rn.f32 	%f138, %f148, %f142;
	// inline asm
	ex2.approx.f32 	%f137, %f138;
	// inline asm
	add.f32 	%f140, %f135, 0f00000000;
	// inline asm
	ex2.approx.f32 	%f139, %f140;
	// inline asm
	mul.rn.f32 	%f149, %f137, %f139;
	setp.lt.f32 	%p18, %f292, 0fC2D20000;
	selp.f32 	%f150, 0f00000000, %f149, %p18;
	setp.gt.f32 	%p19, %f292, 0f42D20000;
	selp.f32 	%f19, %f3, %f150, %p19;
	setp.neu.f32 	%p20, %f19, %f3;
	@%p20 bra 	BB1_16;

	mov.f32 	%f283, %f19;
	bra.uni 	BB1_21;

BB1_16:
	// inline asm
	mad.f32 	%f151, %f19, %f291, %f19;
	// inline asm
	mov.f32 	%f20, %f151;
	mov.f32 	%f283, %f20;
	bra.uni 	BB1_21;

BB1_17:
	@%p3 bra 	BB1_19;

	selp.f32 	%f21, %f4, 0f00000000, %p4;
	mov.f32 	%f283, %f21;
	bra.uni 	BB1_21;

BB1_19:
	mov.f32 	%f283, %f3;
	bra.uni 	BB1_21;

BB1_20:
	mov.f32 	%f283, %f7;

BB1_21:
	mov.f32 	%f22, %f283;
	cvt.rn.f32.s32 	%f156, %r186;
	mul.f32 	%f157, %f156, %f22;
	cvt.rzi.s32.f32 	%r186, %f157;
	add.s32 	%r185, %r185, 1;
	setp.lt.s32 	%p21, %r185, %r9;
	@%p21 bra 	BB1_3;

	cvt.rn.f32.s32 	%f284, %r186;

BB1_23:
	mov.f32 	%f159, 0f41000000;
	// inline asm
	abs.f32 	%f158, %f159;
	// inline asm
	cvt.rn.f32.s32 	%f287, %r10;
	setp.eq.f32 	%p22, %f287, 0f00000000;
	@%p22 bra 	BB1_45;

	setp.nan.f32 	%p23, %f287, %f287;
	@%p23 bra 	BB1_44;

	mov.f32 	%f27, 0f7F800000;
	setp.eq.f32 	%p24, %f287, 0f7F800000;
	setp.eq.f32 	%p25, %f287, 0fFF800000;
	or.pred  	%p26, %p24, %p25;
	@%p26 bra 	BB1_41;

	mov.f32 	%f164, 0f3F000000;
	mul.rn.f32 	%f161, %f164, %f287;
	// inline asm
	cvt.rmi.f32.f32 	%f160, %f161;
	// inline asm
	// inline asm
	cvt.rzi.f32.f32 	%f162, %f287;
	// inline asm
	setp.eq.f32 	%p29, %f158, 0f00000000;
	@%p29 bra 	BB1_38;

	// inline asm
	abs.f32 	%f168, %f159;
	// inline asm
	mov.b32 	 %r22, %f168;
	shr.u32 	%r95, %r22, 23;
	and.b32  	%r96, %r95, 255;
	add.s32 	%r188, %r96, -127;
	setp.eq.s32 	%p30, %r96, 0;
	mov.f32 	%f285, %f168;
	@%p30 bra 	BB1_28;
	bra.uni 	BB1_29;

BB1_28:
	and.b32  	%r97, %r22, -2139095041;
	or.b32  	%r98, %r97, 1065353216;
	mov.b32 	 %f170, %r98;
	add.f32 	%f171, %f170, 0fBF800000;
	mov.b32 	 %r99, %f171;
	shr.u32 	%r100, %r99, 23;
	and.b32  	%r101, %r100, 255;
	add.s32 	%r188, %r101, -253;
	and.b32  	%r102, %r99, -2139095041;
	or.b32  	%r103, %r102, 1065353216;
	mov.b32 	 %f285, %r103;

BB1_29:
	mov.b32 	 %r104, %f285;
	and.b32  	%r105, %r104, -2139095041;
	or.b32  	%r106, %r105, 1065353216;
	mov.b32 	 %f286, %r106;
	setp.gt.f32 	%p31, %f286, 0f3FB504F3;
	@%p31 bra 	BB1_30;
	bra.uni 	BB1_31;

BB1_30:
	mul.rn.f32 	%f286, %f286, %f164;
	add.s32 	%r188, %r188, 1;

BB1_31:
	add.f32 	%f181, %f286, 0f3F800000;
	rcp.approx.f32 	%f175, %f181;
	add.f32 	%f174, %f286, 0fBF800000;
	// inline asm
	mul.rz.f32 	%f173, %f174, %f175;
	// inline asm
	mov.f32 	%f182, 0f40000000;
	mul.rn.f32 	%f183, %f182, %f173;
	mul.rn.f32 	%f184, %f183, %f183;
	mov.f32 	%f185, 0f3B18F0FE;
	mul.rn.f32 	%f186, %f185, %f184;
	add.f32 	%f187, %f186, 0f3C4CAF63;
	mul.rn.f32 	%f188, %f187, %f184;
	add.f32 	%f189, %f188, 0f3DAAAABD;
	mul.rn.f32 	%f190, %f189, %f184;
	mul.rn.f32 	%f178, %f190, %f183;
	mov.b32 	 %r107, %f183;
	and.b32  	%r108, %r107, -4096;
	mov.b32 	 %f191, %r108;
	mov.b32 	 %r109, %f174;
	and.b32  	%r110, %r109, -4096;
	mov.b32 	 %f192, %r110;
	sub.f32 	%f193, %f174, %f191;
	mul.rn.f32 	%f194, %f182, %f193;
	sub.f32 	%f195, %f174, %f192;
	mul.rn.f32 	%f196, %f191, %f192;
	sub.f32 	%f197, %f194, %f196;
	mul.rn.f32 	%f198, %f191, %f195;
	sub.f32 	%f199, %f197, %f198;
	mul.rn.f32 	%f200, %f175, %f199;
	add.f32 	%f201, %f191, %f200;
	sub.f32 	%f202, %f201, %f191;
	sub.f32 	%f203, %f200, %f202;
	add.f32 	%f204, %f201, %f178;
	sub.f32 	%f177, %f201, %f204;
	// inline asm
	add.rz.f32 	%f176, %f177, %f178;
	// inline asm
	add.f32 	%f205, %f176, %f203;
	add.f32 	%f206, %f204, %f205;
	sub.f32 	%f207, %f204, %f206;
	add.f32 	%f208, %f207, %f205;
	cvt.rn.f32.s32 	%f209, %r188;
	mov.f32 	%f210, 0f3F317200;
	mul.rn.f32 	%f211, %f209, %f210;
	mov.f32 	%f212, 0f35BFBE8E;
	mul.rn.f32 	%f213, %f209, %f212;
	add.f32 	%f214, %f211, %f206;
	sub.f32 	%f215, %f211, %f214;
	add.f32 	%f216, %f215, %f206;
	add.f32 	%f217, %f216, %f208;
	add.f32 	%f218, %f217, %f213;
	add.f32 	%f34, %f214, %f218;
	sub.f32 	%f219, %f214, %f34;
	add.f32 	%f35, %f219, %f218;
	// inline asm
	abs.f32 	%f179, %f287;
	// inline asm
	setp.gt.f32 	%p32, %f179, 0f77F684DF;
	@%p32 bra 	BB1_32;
	bra.uni 	BB1_33;

BB1_32:
	mov.f32 	%f220, 0f39000000;
	mul.rn.f32 	%f287, %f287, %f220;

BB1_33:
	mov.f32 	%f221, 0f45800800;
	mul.rn.f32 	%f222, %f34, %f221;
	sub.f32 	%f223, %f34, %f222;
	add.f32 	%f224, %f223, %f222;
	sub.f32 	%f225, %f34, %f224;
	mul.rn.f32 	%f226, %f287, %f221;
	sub.f32 	%f227, %f287, %f226;
	add.f32 	%f228, %f227, %f226;
	sub.f32 	%f229, %f287, %f228;
	mul.rn.f32 	%f230, %f224, %f228;
	mul.rn.f32 	%f231, %f34, %f287;
	sub.f32 	%f232, %f230, %f231;
	mul.rn.f32 	%f233, %f224, %f229;
	add.f32 	%f234, %f232, %f233;
	mul.rn.f32 	%f235, %f225, %f228;
	add.f32 	%f236, %f234, %f235;
	mul.rn.f32 	%f237, %f225, %f229;
	add.f32 	%f238, %f236, %f237;
	mul.rn.f32 	%f239, %f35, %f287;
	add.f32 	%f240, %f239, %f238;
	add.f32 	%f241, %f231, %f240;
	sub.f32 	%f242, %f231, %f241;
	add.f32 	%f38, %f242, %f240;
	mov.f32 	%f289, %f38;
	mov.f32 	%f290, %f241;
	mov.b32 	 %r28, %f241;
	setp.eq.s32 	%p33, %r28, 1118925336;
	@%p33 bra 	BB1_34;
	bra.uni 	BB1_35;

BB1_34:
	add.s32 	%r111, %r28, -1;
	mov.b32 	 %f243, %r111;
	add.f32 	%f244, %f38, 0f37000000;
	mov.f32 	%f289, %f244;
	mov.f32 	%f290, %f243;

BB1_35:
	mov.f32 	%f252, 0f3FB8AA3B;
	mul.rn.f32 	%f246, %f290, %f252;
	// inline asm
	cvt.rzi.f32.f32 	%f245, %f246;
	// inline asm
	mul.rn.f32 	%f254, %f245, %f210;
	sub.f32 	%f255, %f290, %f254;
	mul.rn.f32 	%f257, %f245, %f212;
	sub.f32 	%f258, %f255, %f257;
	mul.rn.f32 	%f248, %f258, %f252;
	// inline asm
	ex2.approx.f32 	%f247, %f248;
	// inline asm
	add.f32 	%f250, %f245, 0f00000000;
	// inline asm
	ex2.approx.f32 	%f249, %f250;
	// inline asm
	mul.rn.f32 	%f259, %f247, %f249;
	setp.lt.f32 	%p34, %f290, 0fC2D20000;
	selp.f32 	%f260, 0f00000000, %f259, %p34;
	setp.gt.f32 	%p35, %f290, 0f42D20000;
	selp.f32 	%f39, %f27, %f260, %p35;
	setp.neu.f32 	%p36, %f39, %f27;
	@%p36 bra 	BB1_37;

	mov.f32 	%f288, %f39;
	bra.uni 	BB1_46;

BB1_37:
	// inline asm
	mad.f32 	%f261, %f39, %f289, %f39;
	// inline asm
	mov.f32 	%f288, %f261;
	bra.uni 	BB1_46;

BB1_38:
	setp.lt.f32 	%p37, %f287, 0f00000000;
	@%p37 bra 	BB1_40;

	mov.f32 	%f288, 0f00000000;
	bra.uni 	BB1_46;

BB1_40:
	mov.f32 	%f288, %f27;
	bra.uni 	BB1_46;

BB1_41:
	setp.lt.f32 	%p38, %f158, 0f3F800000;
	mov.b32 	 %r112, %f287;
	setp.lt.s32 	%p6, %r112, 0;
	@%p38 bra 	BB1_43;

	selp.f32 	%f288, 0f00000000, %f27, %p6;
	bra.uni 	BB1_46;

BB1_43:
	selp.f32 	%f288, %f27, 0f00000000, %p6;
	bra.uni 	BB1_46;

BB1_44:
	add.f32 	%f288, %f287, 0f41000000;
	bra.uni 	BB1_46;

BB1_45:
	mov.f32 	%f288, 0f3F800000;

BB1_46:
	mul.f32 	%f267, %f284, %f288;
	cvt.rzi.s32.f32 	%r29, %f267;
	shr.s32 	%r113, %r29, 31;
	shr.u32 	%r114, %r113, 29;
	add.s32 	%r115, %r29, %r114;
	shr.s32 	%r30, %r115, 3;
	ld.param.u32 	%r184, [DIT8C2C_param_6];
	setp.eq.s32 	%p39, %r184, 1;
	@%p39 bra 	BB1_49;

	ld.param.u32 	%r183, [DIT8C2C_param_6];
	setp.ne.s32 	%p40, %r183, 2;
	@%p40 bra 	BB1_50;

	div.s32 	%r191, %r8, %r30;
	ld.param.u32 	%r177, [DIT8C2C_param_3];
	shr.s32 	%r116, %r177, 31;
	shr.u32 	%r117, %r116, 30;
	add.s32 	%r118, %r177, %r117;
	shr.s32 	%r193, %r118, 2;
	div.s32 	%r119, %r177, %r29;
	rem.s32 	%r192, %r8, %r30;
	mul.lo.s32 	%r194, %r119, %r192;
	ld.param.u32 	%r190, [DIT8C2C_param_2];
	mov.u32 	%r189, %r7;
	bra.uni 	BB1_51;

BB1_49:
	ld.param.u32 	%r176, [DIT8C2C_param_2];
	mul.lo.s32 	%r35, %r8, %r176;
	div.s32 	%r191, %r7, %r30;
	shr.s32 	%r121, %r176, 31;
	shr.u32 	%r122, %r121, 30;
	add.s32 	%r123, %r176, %r122;
	shr.s32 	%r193, %r123, 2;
	div.s32 	%r124, %r176, %r29;
	rem.s32 	%r192, %r7, %r30;
	mul.lo.s32 	%r194, %r124, %r192;
	mov.u32 	%r190, 1;
	mov.u32 	%r189, %r35;
	bra.uni 	BB1_51;

BB1_50:
	mov.u32 	%r194, %r131;
	mov.u32 	%r193, %r132;
	mov.u32 	%r192, %r133;
	mov.u32 	%r191, %r134;
	mov.u32 	%r190, 1;
	mov.u32 	%r189, 0;

BB1_51:
	mad.lo.s32 	%r136, %r191, %r29, %r192;
	mad.lo.s32 	%r137, %r136, %r190, %r189;
	shl.b32 	%r138, %r137, 4;
	ld.param.u32 	%r167, [DIT8C2C_param_0];
	add.s32 	%r46, %r167, %r138;
	ld.global.f64 	%fd17, [%r46];
	ld.global.f64 	%fd18, [%r46+8];
	mul.lo.s32 	%r139, %r190, %r30;
	shl.b32 	%r140, %r139, 4;
	add.s32 	%r47, %r46, %r140;
	ld.global.f64 	%fd19, [%r47];
	ld.global.f64 	%fd20, [%r47+8];
	add.s32 	%r48, %r47, %r140;
	ld.global.f64 	%fd21, [%r48];
	ld.global.f64 	%fd22, [%r48+8];
	add.s32 	%r49, %r48, %r140;
	ld.global.f64 	%fd23, [%r49];
	ld.global.f64 	%fd24, [%r49+8];
	add.s32 	%r50, %r49, %r140;
	ld.global.f64 	%fd1, [%r50];
	ld.global.f64 	%fd2, [%r50+8];
	add.s32 	%r51, %r50, %r140;
	ld.global.f64 	%fd25, [%r51];
	ld.global.f64 	%fd26, [%r51+8];
	add.s32 	%r52, %r51, %r140;
	ld.global.f64 	%fd27, [%r52];
	ld.global.f64 	%fd28, [%r52+8];
	add.s32 	%r53, %r52, %r140;
	ld.global.f64 	%fd29, [%r53];
	ld.global.f64 	%fd30, [%r53+8];
	rem.s32 	%r141, %r194, %r193;
	shl.b32 	%r142, %r141, 4;
	ld.param.u32 	%r174, [DIT8C2C_param_1];
	add.s32 	%r54, %r174, %r142;
	div.s32 	%r135, %r194, %r193;
	setp.eq.s32 	%p41, %r135, 0;
	mov.f64 	%fd832, %fd17;
	mov.f64 	%fd833, %fd18;
	mov.f64 	%fd838, %fd19;
	mov.f64 	%fd839, %fd20;
	mov.f64 	%fd830, %fd21;
	mov.f64 	%fd831, %fd22;
	mov.f64 	%fd836, %fd23;
	mov.f64 	%fd837, %fd24;
	mov.f64 	%fd840, %fd1;
	mov.f64 	%fd841, %fd2;
	mov.f64 	%fd842, %fd25;
	mov.f64 	%fd843, %fd26;
	mov.f64 	%fd828, %fd27;
	mov.f64 	%fd829, %fd28;
	mov.f64 	%fd834, %fd29;
	mov.f64 	%fd835, %fd30;
	@%p41 bra 	BB1_56;

	setp.eq.s32 	%p42, %r135, 1;
	@%p42 bra 	BB1_55;

	setp.ne.s32 	%p43, %r135, 2;
	@%p43 bra 	BB1_57;

	ld.global.v2.f64 	{%fd794, %fd795}, [%r54];
	neg.f64 	%fd32, %fd794;
	neg.f64 	%fd34, %fd795;
	mov.f64 	%fd844, %fd32;
	mov.f64 	%fd845, %fd34;
	bra.uni 	BB1_57;

BB1_55:
	ld.global.v2.f64 	{%fd792, %fd793}, [%r54];
	neg.f64 	%fd37, %fd792;
	mov.f64 	%fd844, %fd793;
	mov.f64 	%fd845, %fd37;
	bra.uni 	BB1_57;

BB1_56:
	ld.global.v2.f64 	{%fd844, %fd845}, [%r54];

BB1_57:
	ld.param.u32 	%r182, [DIT8C2C_param_5];
	setp.eq.s32 	%p7, %r182, 0;
	@%p7 bra 	BB1_58;
	bra.uni 	BB1_59;

BB1_58:
	neg.f64 	%fd39, %fd845;
	mov.f64 	%fd844, %fd844;
	mov.f64 	%fd845, %fd39;

BB1_59:
	setp.eq.s32 	%p8, %r192, 0;
	@%p8 bra 	BB1_61;

	mul.f64 	%fd41, %fd1, %fd844;
	neg.f64 	%fd43, %fd2;
	fma.rn.f64 	%fd44, %fd43, %fd845, %fd41;
	mul.f64 	%fd45, %fd2, %fd844;
	fma.rn.f64 	%fd46, %fd1, %fd845, %fd45;
	mov.f64 	%fd832, %fd17;
	mov.f64 	%fd833, %fd18;
	mov.f64 	%fd838, %fd19;
	mov.f64 	%fd839, %fd20;
	mov.f64 	%fd830, %fd21;
	mov.f64 	%fd831, %fd22;
	mov.f64 	%fd836, %fd23;
	mov.f64 	%fd837, %fd24;
	mov.f64 	%fd842, %fd25;
	mov.f64 	%fd843, %fd26;
	mov.f64 	%fd828, %fd27;
	mov.f64 	%fd829, %fd28;
	mov.f64 	%fd840, %fd44;
	mov.f64 	%fd841, %fd46;
	mov.f64 	%fd834, %fd29;
	mov.f64 	%fd835, %fd30;

BB1_61:
	shl.b32 	%r144, %r194, 1;
	div.s32 	%r143, %r144, %r193;
	rem.s32 	%r145, %r144, %r193;
	shl.b32 	%r146, %r145, 4;
	ld.param.u32 	%r173, [DIT8C2C_param_1];
	add.s32 	%r55, %r173, %r146;
	setp.eq.s32 	%p44, %r143, 0;
	@%p44 bra 	BB1_66;

	setp.eq.s32 	%p45, %r143, 1;
	@%p45 bra 	BB1_65;

	setp.ne.s32 	%p46, %r143, 2;
	@%p46 bra 	BB1_67;

	ld.global.v2.f64 	{%fd744, %fd745}, [%r55];
	neg.f64 	%fd48, %fd744;
	neg.f64 	%fd50, %fd745;
	mov.f64 	%fd844, %fd48;
	mov.f64 	%fd845, %fd50;
	bra.uni 	BB1_67;

BB1_65:
	ld.global.v2.f64 	{%fd742, %fd743}, [%r55];
	neg.f64 	%fd53, %fd742;
	mov.f64 	%fd844, %fd743;
	mov.f64 	%fd845, %fd53;
	bra.uni 	BB1_67;

BB1_66:
	ld.global.v2.f64 	{%fd844, %fd845}, [%r55];

BB1_67:
	@%p7 bra 	BB1_68;
	bra.uni 	BB1_69;

BB1_68:
	neg.f64 	%fd55, %fd845;
	mov.f64 	%fd844, %fd844;
	mov.f64 	%fd845, %fd55;

BB1_69:
	@%p8 bra 	BB1_71;

	mul.f64 	%fd58, %fd830, %fd844;
	neg.f64 	%fd61, %fd831;
	fma.rn.f64 	%fd62, %fd61, %fd845, %fd58;
	mul.f64 	%fd63, %fd831, %fd844;
	fma.rn.f64 	%fd64, %fd830, %fd845, %fd63;
	mov.f64 	%fd830, %fd62;
	mov.f64 	%fd831, %fd64;

BB1_71:
	mul.lo.s32 	%r148, %r194, 3;
	div.s32 	%r147, %r148, %r193;
	rem.s32 	%r149, %r148, %r193;
	shl.b32 	%r150, %r149, 4;
	ld.param.u32 	%r172, [DIT8C2C_param_1];
	add.s32 	%r56, %r172, %r150;
	setp.eq.s32 	%p47, %r147, 0;
	@%p47 bra 	BB1_76;

	setp.eq.s32 	%p48, %r147, 1;
	@%p48 bra 	BB1_75;

	setp.ne.s32 	%p49, %r147, 2;
	@%p49 bra 	BB1_77;

	ld.global.v2.f64 	{%fd694, %fd695}, [%r56];
	neg.f64 	%fd66, %fd694;
	neg.f64 	%fd68, %fd695;
	mov.f64 	%fd844, %fd66;
	mov.f64 	%fd845, %fd68;
	bra.uni 	BB1_77;

BB1_75:
	ld.global.v2.f64 	{%fd692, %fd693}, [%r56];
	neg.f64 	%fd71, %fd692;
	mov.f64 	%fd844, %fd693;
	mov.f64 	%fd845, %fd71;
	bra.uni 	BB1_77;

BB1_76:
	ld.global.v2.f64 	{%fd844, %fd845}, [%r56];

BB1_77:
	@%p7 bra 	BB1_78;
	bra.uni 	BB1_79;

BB1_78:
	neg.f64 	%fd73, %fd845;
	mov.f64 	%fd844, %fd844;
	mov.f64 	%fd845, %fd73;

BB1_79:
	@%p8 bra 	BB1_81;

	mul.f64 	%fd76, %fd828, %fd844;
	neg.f64 	%fd79, %fd829;
	fma.rn.f64 	%fd80, %fd79, %fd845, %fd76;
	mul.f64 	%fd81, %fd829, %fd844;
	fma.rn.f64 	%fd82, %fd828, %fd845, %fd81;
	mov.f64 	%fd828, %fd80;
	mov.f64 	%fd829, %fd82;

BB1_81:
	shl.b32 	%r152, %r194, 2;
	div.s32 	%r151, %r152, %r193;
	rem.s32 	%r153, %r152, %r193;
	shl.b32 	%r154, %r153, 4;
	ld.param.u32 	%r171, [DIT8C2C_param_1];
	add.s32 	%r57, %r171, %r154;
	setp.eq.s32 	%p50, %r151, 0;
	@%p50 bra 	BB1_86;

	setp.eq.s32 	%p51, %r151, 1;
	@%p51 bra 	BB1_85;

	setp.ne.s32 	%p52, %r151, 2;
	@%p52 bra 	BB1_87;

	ld.global.v2.f64 	{%fd644, %fd645}, [%r57];
	neg.f64 	%fd84, %fd644;
	neg.f64 	%fd86, %fd645;
	mov.f64 	%fd844, %fd84;
	mov.f64 	%fd845, %fd86;
	bra.uni 	BB1_87;

BB1_85:
	ld.global.v2.f64 	{%fd642, %fd643}, [%r57];
	neg.f64 	%fd89, %fd642;
	mov.f64 	%fd844, %fd643;
	mov.f64 	%fd845, %fd89;
	bra.uni 	BB1_87;

BB1_86:
	ld.global.v2.f64 	{%fd844, %fd845}, [%r57];

BB1_87:
	@%p7 bra 	BB1_88;
	bra.uni 	BB1_89;

BB1_88:
	neg.f64 	%fd91, %fd845;
	mov.f64 	%fd844, %fd844;
	mov.f64 	%fd845, %fd91;

BB1_89:
	@%p8 bra 	BB1_91;

	mul.f64 	%fd94, %fd838, %fd844;
	neg.f64 	%fd97, %fd839;
	fma.rn.f64 	%fd98, %fd97, %fd845, %fd94;
	mul.f64 	%fd99, %fd839, %fd844;
	fma.rn.f64 	%fd100, %fd838, %fd845, %fd99;
	mov.f64 	%fd838, %fd98;
	mov.f64 	%fd839, %fd100;

BB1_91:
	mul.lo.s32 	%r156, %r194, 5;
	div.s32 	%r155, %r156, %r193;
	rem.s32 	%r157, %r156, %r193;
	shl.b32 	%r158, %r157, 4;
	ld.param.u32 	%r170, [DIT8C2C_param_1];
	add.s32 	%r58, %r170, %r158;
	setp.eq.s32 	%p53, %r155, 0;
	@%p53 bra 	BB1_96;

	setp.eq.s32 	%p54, %r155, 1;
	@%p54 bra 	BB1_95;

	setp.ne.s32 	%p55, %r155, 2;
	@%p55 bra 	BB1_97;

	ld.global.v2.f64 	{%fd594, %fd595}, [%r58];
	neg.f64 	%fd102, %fd594;
	neg.f64 	%fd104, %fd595;
	mov.f64 	%fd844, %fd102;
	mov.f64 	%fd845, %fd104;
	bra.uni 	BB1_97;

BB1_95:
	ld.global.v2.f64 	{%fd592, %fd593}, [%r58];
	neg.f64 	%fd107, %fd592;
	mov.f64 	%fd844, %fd593;
	mov.f64 	%fd845, %fd107;
	bra.uni 	BB1_97;

BB1_96:
	ld.global.v2.f64 	{%fd844, %fd845}, [%r58];

BB1_97:
	@%p7 bra 	BB1_98;
	bra.uni 	BB1_99;

BB1_98:
	neg.f64 	%fd109, %fd845;
	mov.f64 	%fd844, %fd844;
	mov.f64 	%fd845, %fd109;

BB1_99:
	@%p8 bra 	BB1_101;

	mul.f64 	%fd112, %fd842, %fd844;
	neg.f64 	%fd115, %fd843;
	fma.rn.f64 	%fd116, %fd115, %fd845, %fd112;
	mul.f64 	%fd117, %fd843, %fd844;
	fma.rn.f64 	%fd118, %fd842, %fd845, %fd117;
	mov.f64 	%fd842, %fd116;
	mov.f64 	%fd843, %fd118;

BB1_101:
	mul.lo.s32 	%r160, %r194, 6;
	div.s32 	%r159, %r160, %r193;
	rem.s32 	%r161, %r160, %r193;
	shl.b32 	%r162, %r161, 4;
	ld.param.u32 	%r169, [DIT8C2C_param_1];
	add.s32 	%r59, %r169, %r162;
	setp.eq.s32 	%p56, %r159, 0;
	@%p56 bra 	BB1_106;

	setp.eq.s32 	%p57, %r159, 1;
	@%p57 bra 	BB1_105;

	setp.ne.s32 	%p58, %r159, 2;
	@%p58 bra 	BB1_107;

	ld.global.v2.f64 	{%fd544, %fd545}, [%r59];
	neg.f64 	%fd120, %fd544;
	neg.f64 	%fd122, %fd545;
	mov.f64 	%fd844, %fd120;
	mov.f64 	%fd845, %fd122;
	bra.uni 	BB1_107;

BB1_105:
	ld.global.v2.f64 	{%fd542, %fd543}, [%r59];
	neg.f64 	%fd125, %fd542;
	mov.f64 	%fd844, %fd543;
	mov.f64 	%fd845, %fd125;
	bra.uni 	BB1_107;

BB1_106:
	ld.global.v2.f64 	{%fd844, %fd845}, [%r59];

BB1_107:
	@%p7 bra 	BB1_108;
	bra.uni 	BB1_109;

BB1_108:
	neg.f64 	%fd127, %fd845;
	mov.f64 	%fd844, %fd844;
	mov.f64 	%fd845, %fd127;

BB1_109:
	@%p8 bra 	BB1_111;

	mul.f64 	%fd130, %fd836, %fd844;
	neg.f64 	%fd133, %fd837;
	fma.rn.f64 	%fd134, %fd133, %fd845, %fd130;
	mul.f64 	%fd135, %fd837, %fd844;
	fma.rn.f64 	%fd136, %fd836, %fd845, %fd135;
	mov.f64 	%fd836, %fd134;
	mov.f64 	%fd837, %fd136;

BB1_111:
	mul.lo.s32 	%r164, %r194, 7;
	div.s32 	%r163, %r164, %r193;
	rem.s32 	%r165, %r164, %r193;
	shl.b32 	%r166, %r165, 4;
	ld.param.u32 	%r168, [DIT8C2C_param_1];
	add.s32 	%r60, %r168, %r166;
	setp.gt.s32 	%p59, %r163, 1;
	@%p59 bra 	BB1_115;

	setp.eq.s32 	%p62, %r163, 0;
	@%p62 bra 	BB1_119;

	setp.eq.s32 	%p63, %r163, 1;
	@%p63 bra 	BB1_114;
	bra.uni 	BB1_120;

BB1_114:
	ld.global.v2.f64 	{%fd488, %fd489}, [%r60];
	neg.f64 	%fd146, %fd488;
	mov.f64 	%fd844, %fd489;
	mov.f64 	%fd845, %fd146;
	bra.uni 	BB1_120;

BB1_115:
	setp.eq.s32 	%p60, %r163, 2;
	@%p60 bra 	BB1_118;

	setp.ne.s32 	%p61, %r163, 3;
	@%p61 bra 	BB1_120;

	ld.global.v2.f64 	{%fd492, %fd493}, [%r60];
	neg.f64 	%fd138, %fd493;
	mov.f64 	%fd844, %fd138;
	mov.f64 	%fd845, %fd492;
	bra.uni 	BB1_120;

BB1_118:
	ld.global.v2.f64 	{%fd490, %fd491}, [%r60];
	neg.f64 	%fd141, %fd490;
	neg.f64 	%fd143, %fd491;
	mov.f64 	%fd844, %fd141;
	mov.f64 	%fd845, %fd143;
	bra.uni 	BB1_120;

BB1_119:
	ld.global.v2.f64 	{%fd844, %fd845}, [%r60];

BB1_120:
	@%p7 bra 	BB1_121;
	bra.uni 	BB1_122;

BB1_121:
	neg.f64 	%fd148, %fd845;
	mov.f64 	%fd844, %fd844;
	mov.f64 	%fd845, %fd148;

BB1_122:
	@%p8 bra 	BB1_124;

	mul.f64 	%fd151, %fd834, %fd844;
	neg.f64 	%fd154, %fd835;
	fma.rn.f64 	%fd155, %fd154, %fd845, %fd151;
	mul.f64 	%fd156, %fd835, %fd844;
	fma.rn.f64 	%fd157, %fd834, %fd845, %fd156;
	mov.f64 	%fd834, %fd155;
	mov.f64 	%fd835, %fd157;

BB1_124:
	add.f64 	%fd160, %fd832, %fd838;
	add.f64 	%fd163, %fd833, %fd839;
	sub.f64 	%fd164, %fd832, %fd838;
	sub.f64 	%fd165, %fd833, %fd839;
	add.f64 	%fd168, %fd830, %fd836;
	add.f64 	%fd171, %fd831, %fd837;
	sub.f64 	%fd3, %fd830, %fd836;
	sub.f64 	%fd4, %fd831, %fd837;
	add.f64 	%fd174, %fd840, %fd842;
	add.f64 	%fd177, %fd841, %fd843;
	sub.f64 	%fd5, %fd840, %fd842;
	sub.f64 	%fd6, %fd841, %fd843;
	add.f64 	%fd180, %fd828, %fd834;
	add.f64 	%fd183, %fd829, %fd835;
	sub.f64 	%fd7, %fd828, %fd834;
	sub.f64 	%fd8, %fd829, %fd835;
	ld.param.u32 	%r181, [DIT8C2C_param_5];
	setp.eq.s32 	%p64, %r181, 1;
	mov.f64 	%fd814, %fd164;
	mov.f64 	%fd815, %fd165;
	mov.f64 	%fd812, %fd160;
	mov.f64 	%fd813, %fd163;
	mov.f64 	%fd818, %fd3;
	mov.f64 	%fd819, %fd4;
	mov.f64 	%fd816, %fd168;
	mov.f64 	%fd817, %fd171;
	mov.f64 	%fd822, %fd5;
	mov.f64 	%fd823, %fd6;
	mov.f64 	%fd820, %fd174;
	mov.f64 	%fd821, %fd177;
	mov.f64 	%fd826, %fd7;
	mov.f64 	%fd827, %fd8;
	mov.f64 	%fd824, %fd180;
	mov.f64 	%fd825, %fd183;
	@%p64 bra 	BB1_127;

	ld.param.u32 	%r180, [DIT8C2C_param_5];
	setp.ne.s32 	%p65, %r180, 0;
	@%p65 bra 	BB1_128;

	sub.f64 	%fd184, %fd5, %fd6;
	mul.f64 	%fd185, %fd184, 0d3FE6A09E667F3BCD;
	add.f64 	%fd186, %fd8, %fd7;
	mul.f64 	%fd187, %fd186, 0dBFE6A09E667F3BCD;
	add.f64 	%fd188, %fd6, %fd5;
	mul.f64 	%fd189, %fd188, 0d3FE6A09E667F3BCD;
	sub.f64 	%fd190, %fd7, %fd8;
	mul.f64 	%fd191, %fd190, 0d3FE6A09E667F3BCD;
	neg.f64 	%fd192, %fd4;
	mov.f64 	%fd812, %fd160;
	mov.f64 	%fd813, %fd163;
	mov.f64 	%fd814, %fd164;
	mov.f64 	%fd815, %fd165;
	mov.f64 	%fd816, %fd168;
	mov.f64 	%fd817, %fd171;
	mov.f64 	%fd820, %fd174;
	mov.f64 	%fd821, %fd177;
	mov.f64 	%fd818, %fd192;
	mov.f64 	%fd819, %fd3;
	mov.f64 	%fd824, %fd180;
	mov.f64 	%fd825, %fd183;
	mov.f64 	%fd822, %fd185;
	mov.f64 	%fd823, %fd189;
	mov.f64 	%fd826, %fd187;
	mov.f64 	%fd827, %fd191;
	bra.uni 	BB1_128;

BB1_127:
	add.f64 	%fd193, %fd5, %fd6;
	mul.f64 	%fd194, %fd193, 0d3FE6A09E667F3BCD;
	sub.f64 	%fd195, %fd8, %fd7;
	mul.f64 	%fd196, %fd195, 0d3FE6A09E667F3BCD;
	sub.f64 	%fd197, %fd6, %fd5;
	mul.f64 	%fd198, %fd197, 0d3FE6A09E667F3BCD;
	add.f64 	%fd199, %fd8, %fd7;
	mul.f64 	%fd200, %fd199, 0dBFE6A09E667F3BCD;
	neg.f64 	%fd201, %fd3;
	mov.f64 	%fd812, %fd160;
	mov.f64 	%fd813, %fd163;
	mov.f64 	%fd814, %fd164;
	mov.f64 	%fd815, %fd165;
	mov.f64 	%fd816, %fd168;
	mov.f64 	%fd817, %fd171;
	mov.f64 	%fd820, %fd174;
	mov.f64 	%fd821, %fd177;
	mov.f64 	%fd818, %fd4;
	mov.f64 	%fd819, %fd201;
	mov.f64 	%fd824, %fd180;
	mov.f64 	%fd825, %fd183;
	mov.f64 	%fd822, %fd194;
	mov.f64 	%fd823, %fd198;
	mov.f64 	%fd826, %fd196;
	mov.f64 	%fd827, %fd200;

BB1_128:
	add.f64 	%fd204, %fd812, %fd816;
	add.f64 	%fd207, %fd813, %fd817;
	add.f64 	%fd210, %fd814, %fd818;
	add.f64 	%fd213, %fd815, %fd819;
	sub.f64 	%fd214, %fd812, %fd816;
	sub.f64 	%fd215, %fd813, %fd817;
	sub.f64 	%fd216, %fd814, %fd818;
	sub.f64 	%fd217, %fd815, %fd819;
	add.f64 	%fd218, %fd820, %fd824;
	add.f64 	%fd219, %fd821, %fd825;
	add.f64 	%fd220, %fd822, %fd826;
	add.f64 	%fd221, %fd823, %fd827;
	ld.param.u32 	%r179, [DIT8C2C_param_5];
	setp.eq.s32 	%p66, %r179, 1;
	mov.f64 	%fd808, %fd828;
	mov.f64 	%fd809, %fd829;
	mov.f64 	%fd800, %fd214;
	mov.f64 	%fd801, %fd215;
	mov.f64 	%fd796, %fd204;
	mov.f64 	%fd797, %fd207;
	mov.f64 	%fd810, %fd834;
	mov.f64 	%fd811, %fd835;
	mov.f64 	%fd802, %fd216;
	mov.f64 	%fd803, %fd217;
	mov.f64 	%fd798, %fd210;
	mov.f64 	%fd799, %fd213;
	mov.f64 	%fd804, %fd218;
	mov.f64 	%fd805, %fd219;
	mov.f64 	%fd806, %fd220;
	mov.f64 	%fd807, %fd221;
	@%p66 bra 	BB1_131;

	ld.param.u32 	%r178, [DIT8C2C_param_5];
	setp.ne.s32 	%p67, %r178, 0;
	@%p67 bra 	BB1_132;

	sub.f64 	%fd222, %fd825, %fd821;
	sub.f64 	%fd223, %fd820, %fd824;
	sub.f64 	%fd224, %fd827, %fd823;
	sub.f64 	%fd225, %fd822, %fd826;
	mov.f64 	%fd796, %fd204;
	mov.f64 	%fd797, %fd207;
	mov.f64 	%fd798, %fd210;
	mov.f64 	%fd799, %fd213;
	mov.f64 	%fd800, %fd214;
	mov.f64 	%fd801, %fd215;
	mov.f64 	%fd802, %fd216;
	mov.f64 	%fd803, %fd217;
	mov.f64 	%fd804, %fd218;
	mov.f64 	%fd805, %fd219;
	mov.f64 	%fd806, %fd220;
	mov.f64 	%fd807, %fd221;
	mov.f64 	%fd808, %fd222;
	mov.f64 	%fd809, %fd223;
	mov.f64 	%fd810, %fd224;
	mov.f64 	%fd811, %fd225;
	bra.uni 	BB1_132;

BB1_131:
	sub.f64 	%fd226, %fd821, %fd825;
	sub.f64 	%fd227, %fd824, %fd820;
	sub.f64 	%fd228, %fd823, %fd827;
	sub.f64 	%fd229, %fd826, %fd822;
	mov.f64 	%fd796, %fd204;
	mov.f64 	%fd797, %fd207;
	mov.f64 	%fd798, %fd210;
	mov.f64 	%fd799, %fd213;
	mov.f64 	%fd800, %fd214;
	mov.f64 	%fd801, %fd215;
	mov.f64 	%fd802, %fd216;
	mov.f64 	%fd803, %fd217;
	mov.f64 	%fd804, %fd218;
	mov.f64 	%fd805, %fd219;
	mov.f64 	%fd806, %fd220;
	mov.f64 	%fd807, %fd221;
	mov.f64 	%fd808, %fd226;
	mov.f64 	%fd809, %fd227;
	mov.f64 	%fd810, %fd228;
	mov.f64 	%fd811, %fd229;

BB1_132:
	add.f64 	%fd232, %fd796, %fd804;
	st.global.f64 	[%r46], %fd232;
	add.f64 	%fd235, %fd797, %fd805;
	st.global.f64 	[%r46+8], %fd235;
	add.f64 	%fd238, %fd798, %fd806;
	st.global.f64 	[%r47], %fd238;
	add.f64 	%fd241, %fd799, %fd807;
	st.global.f64 	[%r47+8], %fd241;
	add.f64 	%fd244, %fd800, %fd808;
	st.global.f64 	[%r48], %fd244;
	add.f64 	%fd247, %fd801, %fd809;
	st.global.f64 	[%r48+8], %fd247;
	add.f64 	%fd250, %fd802, %fd810;
	st.global.f64 	[%r49], %fd250;
	add.f64 	%fd253, %fd803, %fd811;
	st.global.f64 	[%r49+8], %fd253;
	sub.f64 	%fd254, %fd796, %fd804;
	st.global.f64 	[%r50], %fd254;
	sub.f64 	%fd255, %fd797, %fd805;
	st.global.f64 	[%r50+8], %fd255;
	sub.f64 	%fd256, %fd798, %fd806;
	st.global.f64 	[%r51], %fd256;
	sub.f64 	%fd257, %fd799, %fd807;
	st.global.f64 	[%r51+8], %fd257;
	sub.f64 	%fd258, %fd800, %fd808;
	st.global.f64 	[%r52], %fd258;
	sub.f64 	%fd259, %fd801, %fd809;
	st.global.f64 	[%r52+8], %fd259;
	sub.f64 	%fd260, %fd802, %fd810;
	st.global.f64 	[%r53], %fd260;
	sub.f64 	%fd261, %fd803, %fd811;
	st.global.f64 	[%r53+8], %fd261;
	ret;
}

.entry DIT4C2C(
	.param .u32 .ptr .global .align 8 DIT4C2C_param_0,
	.param .u32 .ptr .global .align 16 DIT4C2C_param_1,
	.param .u32 DIT4C2C_param_2,
	.param .u32 DIT4C2C_param_3,
	.param .u32 DIT4C2C_param_4,
	.param .u32 DIT4C2C_param_5,
	.param .u32 DIT4C2C_param_6
)
{
	.reg .f32 	%f<293>;
	.reg .f64 	%fd<266>;
	.reg .pred 	%p<58>;
	.reg .s32 	%r<166>;


	ld.param.u32 	%r61, [DIT4C2C_param_4];
	// inline asm
	mov.u32 	%r53, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r54, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r55, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r56, %tid.x;
	// inline asm
	add.s32 	%r62, %r56, %r53;
	mad.lo.s32 	%r7, %r55, %r54, %r62;
	// inline asm
	mov.u32 	%r57, %envreg4;
	// inline asm
	// inline asm
	mov.u32 	%r58, %ntid.y;
	// inline asm
	// inline asm
	mov.u32 	%r59, %ctaid.y;
	// inline asm
	// inline asm
	mov.u32 	%r60, %tid.y;
	// inline asm
	add.s32 	%r63, %r60, %r57;
	mad.lo.s32 	%r8, %r59, %r58, %r63;
	mul.hi.s32 	%r64, %r61, -1840700269;
	add.s32 	%r65, %r64, %r61;
	shr.u32 	%r66, %r65, 31;
	shr.s32 	%r67, %r65, 2;
	add.s32 	%r9, %r67, %r66;
	mul.lo.s32 	%r68, %r9, 7;
	sub.s32 	%r10, %r61, %r68;
	setp.gt.s32 	%p9, %r61, 6;
	@%p9 bra 	BB2_2;

	mov.f32 	%f284, 0f3F800000;
	bra.uni 	BB2_23;

BB2_2:
	mov.f32 	%f1, 0f40E00000;
	mov.pred 	%p3, 0;
	mov.f32 	%f47, 0f40800000;
	add.f32 	%f2, %f47, 0f40E00000;
	mov.f32 	%f3, 0f7F800000;
	mov.f32 	%f4, 0f00000000;
	mov.f32 	%f5, 0f37000000;
	mov.u32 	%r157, 1;
	mov.u32 	%r156, 0;

BB2_3:
	// inline asm
	abs.f32 	%f48, %f47;
	// inline asm
	selp.f32 	%f7, 0f3F800000, %f2, %p3;
	or.pred  	%p10, %p3, %p3;
	@%p10 bra 	BB2_20;

	mov.f32 	%f54, 0f3F000000;
	mul.rn.f32 	%f51, %f54, %f1;
	// inline asm
	cvt.rmi.f32.f32 	%f50, %f51;
	// inline asm
	mov.f32 	%f55, 0f40000000;
	mul.rn.f32 	%f56, %f55, %f50;
	sub.f32 	%f57, %f1, %f56;
	setp.eq.f32 	%p11, %f57, 0f3F800000;
	// inline asm
	cvt.rzi.f32.f32 	%f52, %f1;
	// inline asm
	setp.eq.f32 	%p12, %f1, %f52;
	and.pred  	%p4, %p11, %p12;
	setp.eq.f32 	%p13, %f48, 0f00000000;
	@%p13 bra 	BB2_17;

	// inline asm
	abs.f32 	%f58, %f47;
	// inline asm
	mov.b32 	 %r13, %f58;
	shr.u32 	%r71, %r13, 23;
	and.b32  	%r72, %r71, 255;
	add.s32 	%r158, %r72, -127;
	setp.eq.s32 	%p14, %r72, 0;
	mov.f32 	%f280, %f58;
	@%p14 bra 	BB2_6;
	bra.uni 	BB2_7;

BB2_6:
	and.b32  	%r73, %r13, -2139095041;
	or.b32  	%r74, %r73, 1065353216;
	mov.b32 	 %f60, %r74;
	add.f32 	%f61, %f60, 0fBF800000;
	mov.b32 	 %r75, %f61;
	shr.u32 	%r76, %r75, 23;
	and.b32  	%r77, %r76, 255;
	add.s32 	%r158, %r77, -253;
	and.b32  	%r78, %r75, -2139095041;
	or.b32  	%r79, %r78, 1065353216;
	mov.b32 	 %f280, %r79;

BB2_7:
	mov.b32 	 %r80, %f280;
	and.b32  	%r81, %r80, -2139095041;
	or.b32  	%r82, %r81, 1065353216;
	mov.b32 	 %f281, %r82;
	setp.gt.f32 	%p15, %f281, 0f3FB504F3;
	@%p15 bra 	BB2_8;
	bra.uni 	BB2_9;

BB2_8:
	mul.rn.f32 	%f281, %f281, %f54;
	add.s32 	%r158, %r158, 1;

BB2_9:
	add.f32 	%f71, %f281, 0f3F800000;
	rcp.approx.f32 	%f65, %f71;
	add.f32 	%f64, %f281, 0fBF800000;
	// inline asm
	mul.rz.f32 	%f63, %f64, %f65;
	// inline asm
	mul.rn.f32 	%f73, %f55, %f63;
	mul.rn.f32 	%f74, %f73, %f73;
	mov.f32 	%f75, 0f3B18F0FE;
	mul.rn.f32 	%f76, %f75, %f74;
	add.f32 	%f77, %f76, 0f3C4CAF63;
	mul.rn.f32 	%f78, %f77, %f74;
	add.f32 	%f79, %f78, 0f3DAAAABD;
	mul.rn.f32 	%f80, %f79, %f74;
	mul.rn.f32 	%f68, %f80, %f73;
	mov.b32 	 %r83, %f73;
	and.b32  	%r84, %r83, -4096;
	mov.b32 	 %f81, %r84;
	mov.b32 	 %r85, %f64;
	and.b32  	%r86, %r85, -4096;
	mov.b32 	 %f82, %r86;
	sub.f32 	%f83, %f64, %f81;
	mul.rn.f32 	%f84, %f55, %f83;
	sub.f32 	%f85, %f64, %f82;
	mul.rn.f32 	%f86, %f81, %f82;
	sub.f32 	%f87, %f84, %f86;
	mul.rn.f32 	%f88, %f81, %f85;
	sub.f32 	%f89, %f87, %f88;
	mul.rn.f32 	%f90, %f65, %f89;
	add.f32 	%f91, %f81, %f90;
	sub.f32 	%f92, %f91, %f81;
	sub.f32 	%f93, %f90, %f92;
	add.f32 	%f94, %f91, %f68;
	sub.f32 	%f67, %f91, %f94;
	// inline asm
	add.rz.f32 	%f66, %f67, %f68;
	// inline asm
	add.f32 	%f95, %f66, %f93;
	add.f32 	%f96, %f94, %f95;
	sub.f32 	%f97, %f94, %f96;
	add.f32 	%f98, %f97, %f95;
	cvt.rn.f32.s32 	%f99, %r158;
	mov.f32 	%f100, 0f3F317200;
	mul.rn.f32 	%f101, %f99, %f100;
	mov.f32 	%f102, 0f35BFBE8E;
	mul.rn.f32 	%f103, %f99, %f102;
	add.f32 	%f104, %f101, %f96;
	sub.f32 	%f105, %f101, %f104;
	add.f32 	%f106, %f105, %f96;
	add.f32 	%f107, %f106, %f98;
	add.f32 	%f108, %f107, %f103;
	add.f32 	%f14, %f104, %f108;
	sub.f32 	%f109, %f104, %f14;
	add.f32 	%f15, %f109, %f108;
	// inline asm
	abs.f32 	%f69, %f1;
	// inline asm
	setp.gt.f32 	%p16, %f69, 0f77F684DF;
	@%p16 bra 	BB2_11;

	mov.f32 	%f282, %f1;
	bra.uni 	BB2_12;

BB2_11:
	mov.f32 	%f110, 0f39000000;
	mul.rn.f32 	%f16, %f1, %f110;
	mov.f32 	%f282, %f16;

BB2_12:
	mov.f32 	%f17, %f282;
	mov.f32 	%f111, 0f45800800;
	mul.rn.f32 	%f112, %f14, %f111;
	sub.f32 	%f113, %f14, %f112;
	add.f32 	%f114, %f113, %f112;
	sub.f32 	%f115, %f14, %f114;
	mul.rn.f32 	%f116, %f17, %f111;
	sub.f32 	%f117, %f17, %f116;
	add.f32 	%f118, %f117, %f116;
	sub.f32 	%f119, %f17, %f118;
	mul.rn.f32 	%f120, %f114, %f118;
	mul.rn.f32 	%f121, %f14, %f17;
	sub.f32 	%f122, %f120, %f121;
	mul.rn.f32 	%f123, %f114, %f119;
	add.f32 	%f124, %f122, %f123;
	mul.rn.f32 	%f125, %f115, %f118;
	add.f32 	%f126, %f124, %f125;
	mul.rn.f32 	%f127, %f115, %f119;
	add.f32 	%f128, %f126, %f127;
	mul.rn.f32 	%f129, %f15, %f17;
	add.f32 	%f130, %f129, %f128;
	add.f32 	%f131, %f121, %f130;
	sub.f32 	%f132, %f121, %f131;
	add.f32 	%f18, %f132, %f130;
	mov.f32 	%f291, %f18;
	mov.f32 	%f292, %f131;
	mov.b32 	 %r19, %f131;
	setp.eq.s32 	%p17, %r19, 1118925336;
	@%p17 bra 	BB2_13;
	bra.uni 	BB2_14;

BB2_13:
	add.s32 	%r87, %r19, -1;
	mov.b32 	 %f133, %r87;
	add.f32 	%f134, %f18, %f5;
	mov.f32 	%f291, %f134;
	mov.f32 	%f292, %f133;

BB2_14:
	mov.f32 	%f142, 0f3FB8AA3B;
	mul.rn.f32 	%f136, %f292, %f142;
	// inline asm
	cvt.rzi.f32.f32 	%f135, %f136;
	// inline asm
	mul.rn.f32 	%f144, %f135, %f100;
	sub.f32 	%f145, %f292, %f144;
	mul.rn.f32 	%f147, %f135, %f102;
	sub.f32 	%f148, %f145, %f147;
	mul.rn.f32 	%f138, %f148, %f142;
	// inline asm
	ex2.approx.f32 	%f137, %f138;
	// inline asm
	add.f32 	%f140, %f135, 0f00000000;
	// inline asm
	ex2.approx.f32 	%f139, %f140;
	// inline asm
	mul.rn.f32 	%f149, %f137, %f139;
	setp.lt.f32 	%p18, %f292, 0fC2D20000;
	selp.f32 	%f150, 0f00000000, %f149, %p18;
	setp.gt.f32 	%p19, %f292, 0f42D20000;
	selp.f32 	%f19, %f3, %f150, %p19;
	setp.neu.f32 	%p20, %f19, %f3;
	@%p20 bra 	BB2_16;

	mov.f32 	%f283, %f19;
	bra.uni 	BB2_21;

BB2_16:
	// inline asm
	mad.f32 	%f151, %f19, %f291, %f19;
	// inline asm
	mov.f32 	%f20, %f151;
	mov.f32 	%f283, %f20;
	bra.uni 	BB2_21;

BB2_17:
	@%p3 bra 	BB2_19;

	selp.f32 	%f21, %f4, 0f00000000, %p4;
	mov.f32 	%f283, %f21;
	bra.uni 	BB2_21;

BB2_19:
	mov.f32 	%f283, %f3;
	bra.uni 	BB2_21;

BB2_20:
	mov.f32 	%f283, %f7;

BB2_21:
	mov.f32 	%f22, %f283;
	cvt.rn.f32.s32 	%f156, %r157;
	mul.f32 	%f157, %f156, %f22;
	cvt.rzi.s32.f32 	%r157, %f157;
	add.s32 	%r156, %r156, 1;
	setp.lt.s32 	%p21, %r156, %r9;
	@%p21 bra 	BB2_3;

	cvt.rn.f32.s32 	%f284, %r157;

BB2_23:
	mov.f32 	%f159, 0f40800000;
	// inline asm
	abs.f32 	%f158, %f159;
	// inline asm
	cvt.rn.f32.s32 	%f287, %r10;
	setp.eq.f32 	%p22, %f287, 0f00000000;
	@%p22 bra 	BB2_45;

	setp.nan.f32 	%p23, %f287, %f287;
	@%p23 bra 	BB2_44;

	mov.f32 	%f27, 0f7F800000;
	setp.eq.f32 	%p24, %f287, 0f7F800000;
	setp.eq.f32 	%p25, %f287, 0fFF800000;
	or.pred  	%p26, %p24, %p25;
	@%p26 bra 	BB2_41;

	mov.f32 	%f164, 0f3F000000;
	mul.rn.f32 	%f161, %f164, %f287;
	// inline asm
	cvt.rmi.f32.f32 	%f160, %f161;
	// inline asm
	// inline asm
	cvt.rzi.f32.f32 	%f162, %f287;
	// inline asm
	setp.eq.f32 	%p29, %f158, 0f00000000;
	@%p29 bra 	BB2_38;

	// inline asm
	abs.f32 	%f168, %f159;
	// inline asm
	mov.b32 	 %r22, %f168;
	shr.u32 	%r88, %r22, 23;
	and.b32  	%r89, %r88, 255;
	add.s32 	%r159, %r89, -127;
	setp.eq.s32 	%p30, %r89, 0;
	mov.f32 	%f285, %f168;
	@%p30 bra 	BB2_28;
	bra.uni 	BB2_29;

BB2_28:
	and.b32  	%r90, %r22, -2139095041;
	or.b32  	%r91, %r90, 1065353216;
	mov.b32 	 %f170, %r91;
	add.f32 	%f171, %f170, 0fBF800000;
	mov.b32 	 %r92, %f171;
	shr.u32 	%r93, %r92, 23;
	and.b32  	%r94, %r93, 255;
	add.s32 	%r159, %r94, -253;
	and.b32  	%r95, %r92, -2139095041;
	or.b32  	%r96, %r95, 1065353216;
	mov.b32 	 %f285, %r96;

BB2_29:
	mov.b32 	 %r97, %f285;
	and.b32  	%r98, %r97, -2139095041;
	or.b32  	%r99, %r98, 1065353216;
	mov.b32 	 %f286, %r99;
	setp.gt.f32 	%p31, %f286, 0f3FB504F3;
	@%p31 bra 	BB2_30;
	bra.uni 	BB2_31;

BB2_30:
	mul.rn.f32 	%f286, %f286, %f164;
	add.s32 	%r159, %r159, 1;

BB2_31:
	add.f32 	%f181, %f286, 0f3F800000;
	rcp.approx.f32 	%f175, %f181;
	add.f32 	%f174, %f286, 0fBF800000;
	// inline asm
	mul.rz.f32 	%f173, %f174, %f175;
	// inline asm
	mov.f32 	%f182, 0f40000000;
	mul.rn.f32 	%f183, %f182, %f173;
	mul.rn.f32 	%f184, %f183, %f183;
	mov.f32 	%f185, 0f3B18F0FE;
	mul.rn.f32 	%f186, %f185, %f184;
	add.f32 	%f187, %f186, 0f3C4CAF63;
	mul.rn.f32 	%f188, %f187, %f184;
	add.f32 	%f189, %f188, 0f3DAAAABD;
	mul.rn.f32 	%f190, %f189, %f184;
	mul.rn.f32 	%f178, %f190, %f183;
	mov.b32 	 %r100, %f183;
	and.b32  	%r101, %r100, -4096;
	mov.b32 	 %f191, %r101;
	mov.b32 	 %r102, %f174;
	and.b32  	%r103, %r102, -4096;
	mov.b32 	 %f192, %r103;
	sub.f32 	%f193, %f174, %f191;
	mul.rn.f32 	%f194, %f182, %f193;
	sub.f32 	%f195, %f174, %f192;
	mul.rn.f32 	%f196, %f191, %f192;
	sub.f32 	%f197, %f194, %f196;
	mul.rn.f32 	%f198, %f191, %f195;
	sub.f32 	%f199, %f197, %f198;
	mul.rn.f32 	%f200, %f175, %f199;
	add.f32 	%f201, %f191, %f200;
	sub.f32 	%f202, %f201, %f191;
	sub.f32 	%f203, %f200, %f202;
	add.f32 	%f204, %f201, %f178;
	sub.f32 	%f177, %f201, %f204;
	// inline asm
	add.rz.f32 	%f176, %f177, %f178;
	// inline asm
	add.f32 	%f205, %f176, %f203;
	add.f32 	%f206, %f204, %f205;
	sub.f32 	%f207, %f204, %f206;
	add.f32 	%f208, %f207, %f205;
	cvt.rn.f32.s32 	%f209, %r159;
	mov.f32 	%f210, 0f3F317200;
	mul.rn.f32 	%f211, %f209, %f210;
	mov.f32 	%f212, 0f35BFBE8E;
	mul.rn.f32 	%f213, %f209, %f212;
	add.f32 	%f214, %f211, %f206;
	sub.f32 	%f215, %f211, %f214;
	add.f32 	%f216, %f215, %f206;
	add.f32 	%f217, %f216, %f208;
	add.f32 	%f218, %f217, %f213;
	add.f32 	%f34, %f214, %f218;
	sub.f32 	%f219, %f214, %f34;
	add.f32 	%f35, %f219, %f218;
	// inline asm
	abs.f32 	%f179, %f287;
	// inline asm
	setp.gt.f32 	%p32, %f179, 0f77F684DF;
	@%p32 bra 	BB2_32;
	bra.uni 	BB2_33;

BB2_32:
	mov.f32 	%f220, 0f39000000;
	mul.rn.f32 	%f287, %f287, %f220;

BB2_33:
	mov.f32 	%f221, 0f45800800;
	mul.rn.f32 	%f222, %f34, %f221;
	sub.f32 	%f223, %f34, %f222;
	add.f32 	%f224, %f223, %f222;
	sub.f32 	%f225, %f34, %f224;
	mul.rn.f32 	%f226, %f287, %f221;
	sub.f32 	%f227, %f287, %f226;
	add.f32 	%f228, %f227, %f226;
	sub.f32 	%f229, %f287, %f228;
	mul.rn.f32 	%f230, %f224, %f228;
	mul.rn.f32 	%f231, %f34, %f287;
	sub.f32 	%f232, %f230, %f231;
	mul.rn.f32 	%f233, %f224, %f229;
	add.f32 	%f234, %f232, %f233;
	mul.rn.f32 	%f235, %f225, %f228;
	add.f32 	%f236, %f234, %f235;
	mul.rn.f32 	%f237, %f225, %f229;
	add.f32 	%f238, %f236, %f237;
	mul.rn.f32 	%f239, %f35, %f287;
	add.f32 	%f240, %f239, %f238;
	add.f32 	%f241, %f231, %f240;
	sub.f32 	%f242, %f231, %f241;
	add.f32 	%f38, %f242, %f240;
	mov.f32 	%f289, %f38;
	mov.f32 	%f290, %f241;
	mov.b32 	 %r28, %f241;
	setp.eq.s32 	%p33, %r28, 1118925336;
	@%p33 bra 	BB2_34;
	bra.uni 	BB2_35;

BB2_34:
	add.s32 	%r104, %r28, -1;
	mov.b32 	 %f243, %r104;
	add.f32 	%f244, %f38, 0f37000000;
	mov.f32 	%f289, %f244;
	mov.f32 	%f290, %f243;

BB2_35:
	mov.f32 	%f252, 0f3FB8AA3B;
	mul.rn.f32 	%f246, %f290, %f252;
	// inline asm
	cvt.rzi.f32.f32 	%f245, %f246;
	// inline asm
	mul.rn.f32 	%f254, %f245, %f210;
	sub.f32 	%f255, %f290, %f254;
	mul.rn.f32 	%f257, %f245, %f212;
	sub.f32 	%f258, %f255, %f257;
	mul.rn.f32 	%f248, %f258, %f252;
	// inline asm
	ex2.approx.f32 	%f247, %f248;
	// inline asm
	add.f32 	%f250, %f245, 0f00000000;
	// inline asm
	ex2.approx.f32 	%f249, %f250;
	// inline asm
	mul.rn.f32 	%f259, %f247, %f249;
	setp.lt.f32 	%p34, %f290, 0fC2D20000;
	selp.f32 	%f260, 0f00000000, %f259, %p34;
	setp.gt.f32 	%p35, %f290, 0f42D20000;
	selp.f32 	%f39, %f27, %f260, %p35;
	setp.neu.f32 	%p36, %f39, %f27;
	@%p36 bra 	BB2_37;

	mov.f32 	%f288, %f39;
	bra.uni 	BB2_46;

BB2_37:
	// inline asm
	mad.f32 	%f261, %f39, %f289, %f39;
	// inline asm
	mov.f32 	%f288, %f261;
	bra.uni 	BB2_46;

BB2_38:
	setp.lt.f32 	%p37, %f287, 0f00000000;
	@%p37 bra 	BB2_40;

	mov.f32 	%f288, 0f00000000;
	bra.uni 	BB2_46;

BB2_40:
	mov.f32 	%f288, %f27;
	bra.uni 	BB2_46;

BB2_41:
	setp.lt.f32 	%p38, %f158, 0f3F800000;
	mov.b32 	 %r105, %f287;
	setp.lt.s32 	%p6, %r105, 0;
	@%p38 bra 	BB2_43;

	selp.f32 	%f288, 0f00000000, %f27, %p6;
	bra.uni 	BB2_46;

BB2_43:
	selp.f32 	%f288, %f27, 0f00000000, %p6;
	bra.uni 	BB2_46;

BB2_44:
	add.f32 	%f288, %f287, 0f40800000;
	bra.uni 	BB2_46;

BB2_45:
	mov.f32 	%f288, 0f3F800000;

BB2_46:
	mul.f32 	%f267, %f284, %f288;
	cvt.rzi.s32.f32 	%r29, %f267;
	shr.s32 	%r106, %r29, 31;
	shr.u32 	%r107, %r106, 30;
	add.s32 	%r108, %r29, %r107;
	shr.s32 	%r30, %r108, 2;
	ld.param.u32 	%r155, [DIT4C2C_param_6];
	setp.eq.s32 	%p39, %r155, 1;
	@%p39 bra 	BB2_49;

	ld.param.u32 	%r154, [DIT4C2C_param_6];
	setp.ne.s32 	%p40, %r154, 2;
	@%p40 bra 	BB2_50;

	div.s32 	%r160, %r8, %r30;
	ld.param.u32 	%r150, [DIT4C2C_param_3];
	shr.s32 	%r109, %r150, 31;
	shr.u32 	%r110, %r109, 30;
	add.s32 	%r111, %r150, %r110;
	shr.s32 	%r162, %r111, 2;
	div.s32 	%r112, %r150, %r29;
	rem.s32 	%r161, %r8, %r30;
	mul.lo.s32 	%r163, %r112, %r161;
	ld.param.u32 	%r165, [DIT4C2C_param_2];
	mov.u32 	%r164, %r7;
	bra.uni 	BB2_51;

BB2_49:
	ld.param.u32 	%r149, [DIT4C2C_param_2];
	mul.lo.s32 	%r35, %r8, %r149;
	div.s32 	%r160, %r7, %r30;
	shr.s32 	%r114, %r149, 31;
	shr.u32 	%r115, %r114, 30;
	add.s32 	%r116, %r149, %r115;
	shr.s32 	%r162, %r116, 2;
	div.s32 	%r117, %r149, %r29;
	rem.s32 	%r161, %r7, %r30;
	mul.lo.s32 	%r163, %r117, %r161;
	mov.u32 	%r165, 1;
	mov.u32 	%r164, %r35;
	bra.uni 	BB2_51;

BB2_50:
	mov.u32 	%r165, 1;
	mov.u32 	%r164, 0;
	mov.u32 	%r163, %r124;
	mov.u32 	%r162, %r125;
	mov.u32 	%r161, %r126;
	mov.u32 	%r160, %r127;

BB2_51:
	mad.lo.s32 	%r129, %r160, %r29, %r161;
	mad.lo.s32 	%r130, %r165, %r129, %r164;
	shl.b32 	%r131, %r130, 4;
	ld.param.u32 	%r144, [DIT4C2C_param_0];
	add.s32 	%r46, %r144, %r131;
	ld.global.f64 	%fd3, [%r46];
	ld.global.f64 	%fd4, [%r46+8];
	mul.lo.s32 	%r132, %r165, %r30;
	shl.b32 	%r133, %r132, 4;
	add.s32 	%r47, %r46, %r133;
	ld.global.f64 	%fd5, [%r47];
	ld.global.f64 	%fd6, [%r47+8];
	add.s32 	%r48, %r47, %r133;
	ld.global.f64 	%fd1, [%r48];
	ld.global.f64 	%fd2, [%r48+8];
	add.s32 	%r49, %r48, %r133;
	ld.global.f64 	%fd7, [%r49];
	ld.global.f64 	%fd8, [%r49+8];
	rem.s32 	%r134, %r163, %r162;
	shl.b32 	%r135, %r134, 4;
	ld.param.u32 	%r147, [DIT4C2C_param_1];
	add.s32 	%r50, %r147, %r135;
	div.s32 	%r128, %r163, %r162;
	setp.gt.s32 	%p41, %r128, 1;
	mov.f64 	%fd256, %fd3;
	mov.f64 	%fd257, %fd4;
	mov.f64 	%fd258, %fd5;
	mov.f64 	%fd259, %fd6;
	mov.f64 	%fd260, %fd1;
	mov.f64 	%fd261, %fd2;
	mov.f64 	%fd262, %fd7;
	mov.f64 	%fd263, %fd8;
	@%p41 bra 	BB2_55;

	setp.eq.s32 	%p44, %r128, 0;
	@%p44 bra 	BB2_59;

	setp.eq.s32 	%p45, %r128, 1;
	@%p45 bra 	BB2_54;
	bra.uni 	BB2_60;

BB2_54:
	ld.global.v2.f64 	{%fd248, %fd249}, [%r50];
	neg.f64 	%fd18, %fd248;
	mov.f64 	%fd264, %fd249;
	mov.f64 	%fd265, %fd18;
	bra.uni 	BB2_60;

BB2_55:
	setp.eq.s32 	%p42, %r128, 2;
	@%p42 bra 	BB2_58;

	setp.ne.s32 	%p43, %r128, 3;
	@%p43 bra 	BB2_60;

	ld.global.v2.f64 	{%fd252, %fd253}, [%r50];
	neg.f64 	%fd10, %fd253;
	mov.f64 	%fd264, %fd10;
	mov.f64 	%fd265, %fd252;
	bra.uni 	BB2_60;

BB2_58:
	ld.global.v2.f64 	{%fd250, %fd251}, [%r50];
	neg.f64 	%fd13, %fd250;
	neg.f64 	%fd15, %fd251;
	mov.f64 	%fd264, %fd13;
	mov.f64 	%fd265, %fd15;
	bra.uni 	BB2_60;

BB2_59:
	ld.global.v2.f64 	{%fd264, %fd265}, [%r50];

BB2_60:
	ld.param.u32 	%r153, [DIT4C2C_param_5];
	setp.eq.s32 	%p7, %r153, 0;
	@%p7 bra 	BB2_61;
	bra.uni 	BB2_62;

BB2_61:
	neg.f64 	%fd20, %fd265;
	mov.f64 	%fd264, %fd264;
	mov.f64 	%fd265, %fd20;

BB2_62:
	setp.eq.s32 	%p8, %r161, 0;
	@%p8 bra 	BB2_64;

	mul.f64 	%fd22, %fd1, %fd264;
	neg.f64 	%fd24, %fd2;
	fma.rn.f64 	%fd25, %fd24, %fd265, %fd22;
	mul.f64 	%fd26, %fd1, %fd265;
	fma.rn.f64 	%fd27, %fd2, %fd264, %fd26;
	mov.f64 	%fd256, %fd3;
	mov.f64 	%fd257, %fd4;
	mov.f64 	%fd258, %fd5;
	mov.f64 	%fd259, %fd6;
	mov.f64 	%fd262, %fd7;
	mov.f64 	%fd263, %fd8;
	mov.f64 	%fd260, %fd25;
	mov.f64 	%fd261, %fd27;

BB2_64:
	shl.b32 	%r137, %r163, 1;
	div.s32 	%r136, %r137, %r162;
	rem.s32 	%r138, %r137, %r162;
	shl.b32 	%r139, %r138, 4;
	ld.param.u32 	%r146, [DIT4C2C_param_1];
	add.s32 	%r51, %r146, %r139;
	setp.gt.s32 	%p46, %r136, 1;
	@%p46 bra 	BB2_68;

	setp.eq.s32 	%p49, %r136, 0;
	@%p49 bra 	BB2_72;

	setp.eq.s32 	%p50, %r136, 1;
	@%p50 bra 	BB2_67;
	bra.uni 	BB2_73;

BB2_67:
	ld.global.v2.f64 	{%fd208, %fd209}, [%r51];
	neg.f64 	%fd37, %fd208;
	mov.f64 	%fd264, %fd209;
	mov.f64 	%fd265, %fd37;
	bra.uni 	BB2_73;

BB2_68:
	setp.eq.s32 	%p47, %r136, 2;
	@%p47 bra 	BB2_71;

	setp.ne.s32 	%p48, %r136, 3;
	@%p48 bra 	BB2_73;

	ld.global.v2.f64 	{%fd212, %fd213}, [%r51];
	neg.f64 	%fd29, %fd213;
	mov.f64 	%fd264, %fd29;
	mov.f64 	%fd265, %fd212;
	bra.uni 	BB2_73;

BB2_71:
	ld.global.v2.f64 	{%fd210, %fd211}, [%r51];
	neg.f64 	%fd32, %fd210;
	neg.f64 	%fd34, %fd211;
	mov.f64 	%fd264, %fd32;
	mov.f64 	%fd265, %fd34;
	bra.uni 	BB2_73;

BB2_72:
	ld.global.v2.f64 	{%fd264, %fd265}, [%r51];

BB2_73:
	@%p7 bra 	BB2_74;
	bra.uni 	BB2_75;

BB2_74:
	neg.f64 	%fd39, %fd265;
	mov.f64 	%fd264, %fd264;
	mov.f64 	%fd265, %fd39;

BB2_75:
	@%p8 bra 	BB2_77;

	mul.f64 	%fd42, %fd258, %fd264;
	neg.f64 	%fd45, %fd259;
	fma.rn.f64 	%fd46, %fd45, %fd265, %fd42;
	mul.f64 	%fd47, %fd258, %fd265;
	fma.rn.f64 	%fd48, %fd259, %fd264, %fd47;
	mov.f64 	%fd258, %fd46;
	mov.f64 	%fd259, %fd48;

BB2_77:
	mul.lo.s32 	%r141, %r163, 3;
	div.s32 	%r140, %r141, %r162;
	rem.s32 	%r142, %r141, %r162;
	shl.b32 	%r143, %r142, 4;
	ld.param.u32 	%r145, [DIT4C2C_param_1];
	add.s32 	%r52, %r145, %r143;
	setp.gt.s32 	%p51, %r140, 1;
	@%p51 bra 	BB2_81;

	setp.eq.s32 	%p54, %r140, 0;
	@%p54 bra 	BB2_85;

	setp.eq.s32 	%p55, %r140, 1;
	@%p55 bra 	BB2_80;
	bra.uni 	BB2_86;

BB2_80:
	ld.global.v2.f64 	{%fd168, %fd169}, [%r52];
	neg.f64 	%fd58, %fd168;
	mov.f64 	%fd264, %fd169;
	mov.f64 	%fd265, %fd58;
	bra.uni 	BB2_86;

BB2_81:
	setp.eq.s32 	%p52, %r140, 2;
	@%p52 bra 	BB2_84;

	setp.ne.s32 	%p53, %r140, 3;
	@%p53 bra 	BB2_86;

	ld.global.v2.f64 	{%fd172, %fd173}, [%r52];
	neg.f64 	%fd50, %fd173;
	mov.f64 	%fd264, %fd50;
	mov.f64 	%fd265, %fd172;
	bra.uni 	BB2_86;

BB2_84:
	ld.global.v2.f64 	{%fd170, %fd171}, [%r52];
	neg.f64 	%fd53, %fd170;
	neg.f64 	%fd55, %fd171;
	mov.f64 	%fd264, %fd53;
	mov.f64 	%fd265, %fd55;
	bra.uni 	BB2_86;

BB2_85:
	ld.global.v2.f64 	{%fd264, %fd265}, [%r52];

BB2_86:
	@%p7 bra 	BB2_87;
	bra.uni 	BB2_88;

BB2_87:
	neg.f64 	%fd60, %fd265;
	mov.f64 	%fd264, %fd264;
	mov.f64 	%fd265, %fd60;

BB2_88:
	@%p8 bra 	BB2_90;

	mul.f64 	%fd63, %fd262, %fd264;
	neg.f64 	%fd66, %fd263;
	fma.rn.f64 	%fd67, %fd66, %fd265, %fd63;
	mul.f64 	%fd68, %fd262, %fd265;
	fma.rn.f64 	%fd69, %fd263, %fd264, %fd68;
	mov.f64 	%fd262, %fd67;
	mov.f64 	%fd263, %fd69;

BB2_90:
	ld.param.u32 	%r152, [DIT4C2C_param_5];
	setp.eq.s32 	%p56, %r152, 1;
	@%p56 bra 	BB2_93;

	ld.param.u32 	%r151, [DIT4C2C_param_5];
	setp.ne.s32 	%p57, %r151, 0;
	@%p57 bra 	BB2_94;

	add.f64 	%fd72, %fd256, %fd258;
	add.f64 	%fd74, %fd72, %fd260;
	add.f64 	%fd76, %fd74, %fd262;
	st.global.f64 	[%r46], %fd76;
	add.f64 	%fd79, %fd257, %fd259;
	add.f64 	%fd81, %fd79, %fd261;
	add.f64 	%fd83, %fd81, %fd263;
	st.global.f64 	[%r46+8], %fd83;
	sub.f64 	%fd84, %fd256, %fd258;
	sub.f64 	%fd85, %fd84, %fd261;
	add.f64 	%fd86, %fd85, %fd263;
	st.global.f64 	[%r47], %fd86;
	sub.f64 	%fd87, %fd257, %fd259;
	add.f64 	%fd88, %fd87, %fd260;
	sub.f64 	%fd89, %fd88, %fd262;
	st.global.f64 	[%r47+8], %fd89;
	sub.f64 	%fd90, %fd72, %fd260;
	sub.f64 	%fd91, %fd90, %fd262;
	st.global.f64 	[%r48], %fd91;
	sub.f64 	%fd92, %fd79, %fd261;
	sub.f64 	%fd93, %fd92, %fd263;
	st.global.f64 	[%r48+8], %fd93;
	add.f64 	%fd94, %fd84, %fd261;
	sub.f64 	%fd95, %fd94, %fd263;
	st.global.f64 	[%r49], %fd95;
	sub.f64 	%fd96, %fd87, %fd260;
	add.f64 	%fd97, %fd96, %fd262;
	st.global.f64 	[%r49+8], %fd97;
	ret;

BB2_93:
	add.f64 	%fd100, %fd256, %fd258;
	add.f64 	%fd102, %fd100, %fd260;
	add.f64 	%fd104, %fd102, %fd262;
	st.global.f64 	[%r46], %fd104;
	add.f64 	%fd107, %fd257, %fd259;
	add.f64 	%fd109, %fd107, %fd261;
	add.f64 	%fd111, %fd109, %fd263;
	st.global.f64 	[%r46+8], %fd111;
	sub.f64 	%fd112, %fd256, %fd258;
	add.f64 	%fd113, %fd112, %fd261;
	sub.f64 	%fd114, %fd113, %fd263;
	st.global.f64 	[%r47], %fd114;
	sub.f64 	%fd115, %fd257, %fd259;
	sub.f64 	%fd116, %fd115, %fd260;
	add.f64 	%fd117, %fd116, %fd262;
	st.global.f64 	[%r47+8], %fd117;
	sub.f64 	%fd118, %fd100, %fd260;
	sub.f64 	%fd119, %fd118, %fd262;
	st.global.f64 	[%r48], %fd119;
	sub.f64 	%fd120, %fd107, %fd261;
	sub.f64 	%fd121, %fd120, %fd263;
	st.global.f64 	[%r48+8], %fd121;
	sub.f64 	%fd122, %fd112, %fd261;
	add.f64 	%fd123, %fd122, %fd263;
	st.global.f64 	[%r49], %fd123;
	add.f64 	%fd124, %fd115, %fd260;
	sub.f64 	%fd125, %fd124, %fd262;
	st.global.f64 	[%r49+8], %fd125;

BB2_94:
	ret;
}

.entry DIT2C2C(
	.param .u32 .ptr .global .align 8 DIT2C2C_param_0,
	.param .u32 .ptr .global .align 16 DIT2C2C_param_1,
	.param .u32 DIT2C2C_param_2,
	.param .u32 DIT2C2C_param_3,
	.param .u32 DIT2C2C_param_4,
	.param .u32 DIT2C2C_param_5,
	.param .u32 DIT2C2C_param_6
)
{
	.reg .f32 	%f<293>;
	.reg .f64 	%fd<55>;
	.reg .pred 	%p<45>;
	.reg .s32 	%r<152>;


	ld.param.u32 	%r57, [DIT2C2C_param_4];
	// inline asm
	mov.u32 	%r49, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r50, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r51, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r52, %tid.x;
	// inline asm
	add.s32 	%r58, %r52, %r49;
	mad.lo.s32 	%r7, %r51, %r50, %r58;
	// inline asm
	mov.u32 	%r53, %envreg4;
	// inline asm
	// inline asm
	mov.u32 	%r54, %ntid.y;
	// inline asm
	// inline asm
	mov.u32 	%r55, %ctaid.y;
	// inline asm
	// inline asm
	mov.u32 	%r56, %tid.y;
	// inline asm
	add.s32 	%r59, %r56, %r53;
	mad.lo.s32 	%r8, %r55, %r54, %r59;
	mul.hi.s32 	%r60, %r57, 780903145;
	shr.u32 	%r61, %r60, 31;
	shr.s32 	%r62, %r60, 1;
	add.s32 	%r9, %r62, %r61;
	mul.lo.s32 	%r63, %r9, 11;
	sub.s32 	%r10, %r57, %r63;
	setp.gt.s32 	%p7, %r57, 10;
	@%p7 bra 	BB3_2;

	mov.f32 	%f284, 0f3F800000;
	bra.uni 	BB3_23;

BB3_2:
	mov.f32 	%f1, 0f41300000;
	mov.pred 	%p3, 0;
	mov.f32 	%f47, 0f40000000;
	add.f32 	%f2, %f47, 0f41300000;
	mov.f32 	%f3, 0f7F800000;
	mov.f32 	%f4, 0f00000000;
	mov.f32 	%f5, 0f37000000;
	mov.u32 	%r143, 1;
	mov.u32 	%r142, 0;

BB3_3:
	// inline asm
	abs.f32 	%f48, %f47;
	// inline asm
	selp.f32 	%f7, 0f3F800000, %f2, %p3;
	or.pred  	%p8, %p3, %p3;
	@%p8 bra 	BB3_20;

	mov.f32 	%f54, 0f3F000000;
	mul.rn.f32 	%f51, %f54, %f1;
	// inline asm
	cvt.rmi.f32.f32 	%f50, %f51;
	// inline asm
	mul.rn.f32 	%f56, %f47, %f50;
	sub.f32 	%f57, %f1, %f56;
	setp.eq.f32 	%p9, %f57, 0f3F800000;
	// inline asm
	cvt.rzi.f32.f32 	%f52, %f1;
	// inline asm
	setp.eq.f32 	%p10, %f1, %f52;
	and.pred  	%p4, %p9, %p10;
	setp.eq.f32 	%p11, %f48, 0f00000000;
	@%p11 bra 	BB3_17;

	// inline asm
	abs.f32 	%f58, %f47;
	// inline asm
	mov.b32 	 %r13, %f58;
	shr.u32 	%r66, %r13, 23;
	and.b32  	%r67, %r66, 255;
	add.s32 	%r144, %r67, -127;
	setp.eq.s32 	%p12, %r67, 0;
	mov.f32 	%f280, %f58;
	@%p12 bra 	BB3_6;
	bra.uni 	BB3_7;

BB3_6:
	and.b32  	%r68, %r13, -2139095041;
	or.b32  	%r69, %r68, 1065353216;
	mov.b32 	 %f60, %r69;
	add.f32 	%f61, %f60, 0fBF800000;
	mov.b32 	 %r70, %f61;
	shr.u32 	%r71, %r70, 23;
	and.b32  	%r72, %r71, 255;
	add.s32 	%r144, %r72, -253;
	and.b32  	%r73, %r70, -2139095041;
	or.b32  	%r74, %r73, 1065353216;
	mov.b32 	 %f280, %r74;

BB3_7:
	mov.b32 	 %r75, %f280;
	and.b32  	%r76, %r75, -2139095041;
	or.b32  	%r77, %r76, 1065353216;
	mov.b32 	 %f281, %r77;
	setp.gt.f32 	%p13, %f281, 0f3FB504F3;
	@%p13 bra 	BB3_8;
	bra.uni 	BB3_9;

BB3_8:
	mul.rn.f32 	%f281, %f281, %f54;
	add.s32 	%r144, %r144, 1;

BB3_9:
	add.f32 	%f71, %f281, 0f3F800000;
	rcp.approx.f32 	%f65, %f71;
	add.f32 	%f64, %f281, 0fBF800000;
	// inline asm
	mul.rz.f32 	%f63, %f64, %f65;
	// inline asm
	mul.rn.f32 	%f73, %f47, %f63;
	mul.rn.f32 	%f74, %f73, %f73;
	mov.f32 	%f75, 0f3B18F0FE;
	mul.rn.f32 	%f76, %f75, %f74;
	add.f32 	%f77, %f76, 0f3C4CAF63;
	mul.rn.f32 	%f78, %f77, %f74;
	add.f32 	%f79, %f78, 0f3DAAAABD;
	mul.rn.f32 	%f80, %f79, %f74;
	mul.rn.f32 	%f68, %f80, %f73;
	mov.b32 	 %r78, %f73;
	and.b32  	%r79, %r78, -4096;
	mov.b32 	 %f81, %r79;
	mov.b32 	 %r80, %f64;
	and.b32  	%r81, %r80, -4096;
	mov.b32 	 %f82, %r81;
	sub.f32 	%f83, %f64, %f81;
	mul.rn.f32 	%f84, %f47, %f83;
	sub.f32 	%f85, %f64, %f82;
	mul.rn.f32 	%f86, %f81, %f82;
	sub.f32 	%f87, %f84, %f86;
	mul.rn.f32 	%f88, %f81, %f85;
	sub.f32 	%f89, %f87, %f88;
	mul.rn.f32 	%f90, %f65, %f89;
	add.f32 	%f91, %f81, %f90;
	sub.f32 	%f92, %f91, %f81;
	sub.f32 	%f93, %f90, %f92;
	add.f32 	%f94, %f91, %f68;
	sub.f32 	%f67, %f91, %f94;
	// inline asm
	add.rz.f32 	%f66, %f67, %f68;
	// inline asm
	add.f32 	%f95, %f66, %f93;
	add.f32 	%f96, %f94, %f95;
	sub.f32 	%f97, %f94, %f96;
	add.f32 	%f98, %f97, %f95;
	cvt.rn.f32.s32 	%f99, %r144;
	mov.f32 	%f100, 0f3F317200;
	mul.rn.f32 	%f101, %f99, %f100;
	mov.f32 	%f102, 0f35BFBE8E;
	mul.rn.f32 	%f103, %f99, %f102;
	add.f32 	%f104, %f101, %f96;
	sub.f32 	%f105, %f101, %f104;
	add.f32 	%f106, %f105, %f96;
	add.f32 	%f107, %f106, %f98;
	add.f32 	%f108, %f107, %f103;
	add.f32 	%f14, %f104, %f108;
	sub.f32 	%f109, %f104, %f14;
	add.f32 	%f15, %f109, %f108;
	// inline asm
	abs.f32 	%f69, %f1;
	// inline asm
	setp.gt.f32 	%p14, %f69, 0f77F684DF;
	@%p14 bra 	BB3_11;

	mov.f32 	%f282, %f1;
	bra.uni 	BB3_12;

BB3_11:
	mov.f32 	%f110, 0f39000000;
	mul.rn.f32 	%f16, %f1, %f110;
	mov.f32 	%f282, %f16;

BB3_12:
	mov.f32 	%f17, %f282;
	mov.f32 	%f111, 0f45800800;
	mul.rn.f32 	%f112, %f14, %f111;
	sub.f32 	%f113, %f14, %f112;
	add.f32 	%f114, %f113, %f112;
	sub.f32 	%f115, %f14, %f114;
	mul.rn.f32 	%f116, %f17, %f111;
	sub.f32 	%f117, %f17, %f116;
	add.f32 	%f118, %f117, %f116;
	sub.f32 	%f119, %f17, %f118;
	mul.rn.f32 	%f120, %f114, %f118;
	mul.rn.f32 	%f121, %f14, %f17;
	sub.f32 	%f122, %f120, %f121;
	mul.rn.f32 	%f123, %f114, %f119;
	add.f32 	%f124, %f122, %f123;
	mul.rn.f32 	%f125, %f115, %f118;
	add.f32 	%f126, %f124, %f125;
	mul.rn.f32 	%f127, %f115, %f119;
	add.f32 	%f128, %f126, %f127;
	mul.rn.f32 	%f129, %f15, %f17;
	add.f32 	%f130, %f129, %f128;
	add.f32 	%f131, %f121, %f130;
	sub.f32 	%f132, %f121, %f131;
	add.f32 	%f18, %f132, %f130;
	mov.f32 	%f291, %f18;
	mov.f32 	%f292, %f131;
	mov.b32 	 %r19, %f131;
	setp.eq.s32 	%p15, %r19, 1118925336;
	@%p15 bra 	BB3_13;
	bra.uni 	BB3_14;

BB3_13:
	add.s32 	%r82, %r19, -1;
	mov.b32 	 %f133, %r82;
	add.f32 	%f134, %f18, %f5;
	mov.f32 	%f291, %f134;
	mov.f32 	%f292, %f133;

BB3_14:
	mov.f32 	%f142, 0f3FB8AA3B;
	mul.rn.f32 	%f136, %f292, %f142;
	// inline asm
	cvt.rzi.f32.f32 	%f135, %f136;
	// inline asm
	mul.rn.f32 	%f144, %f135, %f100;
	sub.f32 	%f145, %f292, %f144;
	mul.rn.f32 	%f147, %f135, %f102;
	sub.f32 	%f148, %f145, %f147;
	mul.rn.f32 	%f138, %f148, %f142;
	// inline asm
	ex2.approx.f32 	%f137, %f138;
	// inline asm
	add.f32 	%f140, %f135, 0f00000000;
	// inline asm
	ex2.approx.f32 	%f139, %f140;
	// inline asm
	mul.rn.f32 	%f149, %f137, %f139;
	setp.lt.f32 	%p16, %f292, 0fC2D20000;
	selp.f32 	%f150, 0f00000000, %f149, %p16;
	setp.gt.f32 	%p17, %f292, 0f42D20000;
	selp.f32 	%f19, %f3, %f150, %p17;
	setp.neu.f32 	%p18, %f19, %f3;
	@%p18 bra 	BB3_16;

	mov.f32 	%f283, %f19;
	bra.uni 	BB3_21;

BB3_16:
	// inline asm
	mad.f32 	%f151, %f19, %f291, %f19;
	// inline asm
	mov.f32 	%f20, %f151;
	mov.f32 	%f283, %f20;
	bra.uni 	BB3_21;

BB3_17:
	@%p3 bra 	BB3_19;

	selp.f32 	%f21, %f4, 0f00000000, %p4;
	mov.f32 	%f283, %f21;
	bra.uni 	BB3_21;

BB3_19:
	mov.f32 	%f283, %f3;
	bra.uni 	BB3_21;

BB3_20:
	mov.f32 	%f283, %f7;

BB3_21:
	mov.f32 	%f22, %f283;
	cvt.rn.f32.s32 	%f156, %r143;
	mul.f32 	%f157, %f156, %f22;
	cvt.rzi.s32.f32 	%r143, %f157;
	add.s32 	%r142, %r142, 1;
	setp.lt.s32 	%p19, %r142, %r9;
	@%p19 bra 	BB3_3;

	cvt.rn.f32.s32 	%f284, %r143;

BB3_23:
	mov.f32 	%f159, 0f40000000;
	// inline asm
	abs.f32 	%f158, %f159;
	// inline asm
	cvt.rn.f32.s32 	%f287, %r10;
	setp.eq.f32 	%p20, %f287, 0f00000000;
	@%p20 bra 	BB3_45;

	setp.nan.f32 	%p21, %f287, %f287;
	@%p21 bra 	BB3_44;

	mov.f32 	%f27, 0f7F800000;
	setp.eq.f32 	%p22, %f287, 0f7F800000;
	setp.eq.f32 	%p23, %f287, 0fFF800000;
	or.pred  	%p24, %p22, %p23;
	@%p24 bra 	BB3_41;

	mov.f32 	%f164, 0f3F000000;
	mul.rn.f32 	%f161, %f164, %f287;
	// inline asm
	cvt.rmi.f32.f32 	%f160, %f161;
	// inline asm
	// inline asm
	cvt.rzi.f32.f32 	%f162, %f287;
	// inline asm
	setp.eq.f32 	%p27, %f158, 0f00000000;
	@%p27 bra 	BB3_38;

	// inline asm
	abs.f32 	%f168, %f159;
	// inline asm
	mov.b32 	 %r22, %f168;
	shr.u32 	%r83, %r22, 23;
	and.b32  	%r84, %r83, 255;
	add.s32 	%r145, %r84, -127;
	setp.eq.s32 	%p28, %r84, 0;
	mov.f32 	%f285, %f168;
	@%p28 bra 	BB3_28;
	bra.uni 	BB3_29;

BB3_28:
	and.b32  	%r85, %r22, -2139095041;
	or.b32  	%r86, %r85, 1065353216;
	mov.b32 	 %f170, %r86;
	add.f32 	%f171, %f170, 0fBF800000;
	mov.b32 	 %r87, %f171;
	shr.u32 	%r88, %r87, 23;
	and.b32  	%r89, %r88, 255;
	add.s32 	%r145, %r89, -253;
	and.b32  	%r90, %r87, -2139095041;
	or.b32  	%r91, %r90, 1065353216;
	mov.b32 	 %f285, %r91;

BB3_29:
	mov.b32 	 %r92, %f285;
	and.b32  	%r93, %r92, -2139095041;
	or.b32  	%r94, %r93, 1065353216;
	mov.b32 	 %f286, %r94;
	setp.gt.f32 	%p29, %f286, 0f3FB504F3;
	@%p29 bra 	BB3_30;
	bra.uni 	BB3_31;

BB3_30:
	mul.rn.f32 	%f286, %f286, %f164;
	add.s32 	%r145, %r145, 1;

BB3_31:
	add.f32 	%f181, %f286, 0f3F800000;
	rcp.approx.f32 	%f175, %f181;
	add.f32 	%f174, %f286, 0fBF800000;
	// inline asm
	mul.rz.f32 	%f173, %f174, %f175;
	// inline asm
	mul.rn.f32 	%f183, %f159, %f173;
	mul.rn.f32 	%f184, %f183, %f183;
	mov.f32 	%f185, 0f3B18F0FE;
	mul.rn.f32 	%f186, %f185, %f184;
	add.f32 	%f187, %f186, 0f3C4CAF63;
	mul.rn.f32 	%f188, %f187, %f184;
	add.f32 	%f189, %f188, 0f3DAAAABD;
	mul.rn.f32 	%f190, %f189, %f184;
	mul.rn.f32 	%f178, %f190, %f183;
	mov.b32 	 %r95, %f183;
	and.b32  	%r96, %r95, -4096;
	mov.b32 	 %f191, %r96;
	mov.b32 	 %r97, %f174;
	and.b32  	%r98, %r97, -4096;
	mov.b32 	 %f192, %r98;
	sub.f32 	%f193, %f174, %f191;
	mul.rn.f32 	%f194, %f159, %f193;
	sub.f32 	%f195, %f174, %f192;
	mul.rn.f32 	%f196, %f191, %f192;
	sub.f32 	%f197, %f194, %f196;
	mul.rn.f32 	%f198, %f191, %f195;
	sub.f32 	%f199, %f197, %f198;
	mul.rn.f32 	%f200, %f175, %f199;
	add.f32 	%f201, %f191, %f200;
	sub.f32 	%f202, %f201, %f191;
	sub.f32 	%f203, %f200, %f202;
	add.f32 	%f204, %f201, %f178;
	sub.f32 	%f177, %f201, %f204;
	// inline asm
	add.rz.f32 	%f176, %f177, %f178;
	// inline asm
	add.f32 	%f205, %f176, %f203;
	add.f32 	%f206, %f204, %f205;
	sub.f32 	%f207, %f204, %f206;
	add.f32 	%f208, %f207, %f205;
	cvt.rn.f32.s32 	%f209, %r145;
	mov.f32 	%f210, 0f3F317200;
	mul.rn.f32 	%f211, %f209, %f210;
	mov.f32 	%f212, 0f35BFBE8E;
	mul.rn.f32 	%f213, %f209, %f212;
	add.f32 	%f214, %f211, %f206;
	sub.f32 	%f215, %f211, %f214;
	add.f32 	%f216, %f215, %f206;
	add.f32 	%f217, %f216, %f208;
	add.f32 	%f218, %f217, %f213;
	add.f32 	%f34, %f214, %f218;
	sub.f32 	%f219, %f214, %f34;
	add.f32 	%f35, %f219, %f218;
	// inline asm
	abs.f32 	%f179, %f287;
	// inline asm
	setp.gt.f32 	%p30, %f179, 0f77F684DF;
	@%p30 bra 	BB3_32;
	bra.uni 	BB3_33;

BB3_32:
	mov.f32 	%f220, 0f39000000;
	mul.rn.f32 	%f287, %f287, %f220;

BB3_33:
	mov.f32 	%f221, 0f45800800;
	mul.rn.f32 	%f222, %f34, %f221;
	sub.f32 	%f223, %f34, %f222;
	add.f32 	%f224, %f223, %f222;
	sub.f32 	%f225, %f34, %f224;
	mul.rn.f32 	%f226, %f287, %f221;
	sub.f32 	%f227, %f287, %f226;
	add.f32 	%f228, %f227, %f226;
	sub.f32 	%f229, %f287, %f228;
	mul.rn.f32 	%f230, %f224, %f228;
	mul.rn.f32 	%f231, %f34, %f287;
	sub.f32 	%f232, %f230, %f231;
	mul.rn.f32 	%f233, %f224, %f229;
	add.f32 	%f234, %f232, %f233;
	mul.rn.f32 	%f235, %f225, %f228;
	add.f32 	%f236, %f234, %f235;
	mul.rn.f32 	%f237, %f225, %f229;
	add.f32 	%f238, %f236, %f237;
	mul.rn.f32 	%f239, %f35, %f287;
	add.f32 	%f240, %f239, %f238;
	add.f32 	%f241, %f231, %f240;
	sub.f32 	%f242, %f231, %f241;
	add.f32 	%f38, %f242, %f240;
	mov.f32 	%f289, %f38;
	mov.f32 	%f290, %f241;
	mov.b32 	 %r28, %f241;
	setp.eq.s32 	%p31, %r28, 1118925336;
	@%p31 bra 	BB3_34;
	bra.uni 	BB3_35;

BB3_34:
	add.s32 	%r99, %r28, -1;
	mov.b32 	 %f243, %r99;
	add.f32 	%f244, %f38, 0f37000000;
	mov.f32 	%f289, %f244;
	mov.f32 	%f290, %f243;

BB3_35:
	mov.f32 	%f252, 0f3FB8AA3B;
	mul.rn.f32 	%f246, %f290, %f252;
	// inline asm
	cvt.rzi.f32.f32 	%f245, %f246;
	// inline asm
	mul.rn.f32 	%f254, %f245, %f210;
	sub.f32 	%f255, %f290, %f254;
	mul.rn.f32 	%f257, %f245, %f212;
	sub.f32 	%f258, %f255, %f257;
	mul.rn.f32 	%f248, %f258, %f252;
	// inline asm
	ex2.approx.f32 	%f247, %f248;
	// inline asm
	add.f32 	%f250, %f245, 0f00000000;
	// inline asm
	ex2.approx.f32 	%f249, %f250;
	// inline asm
	mul.rn.f32 	%f259, %f247, %f249;
	setp.lt.f32 	%p32, %f290, 0fC2D20000;
	selp.f32 	%f260, 0f00000000, %f259, %p32;
	setp.gt.f32 	%p33, %f290, 0f42D20000;
	selp.f32 	%f39, %f27, %f260, %p33;
	setp.neu.f32 	%p34, %f39, %f27;
	@%p34 bra 	BB3_37;

	mov.f32 	%f288, %f39;
	bra.uni 	BB3_46;

BB3_37:
	// inline asm
	mad.f32 	%f261, %f39, %f289, %f39;
	// inline asm
	mov.f32 	%f288, %f261;
	bra.uni 	BB3_46;

BB3_38:
	setp.lt.f32 	%p35, %f287, 0f00000000;
	@%p35 bra 	BB3_40;

	mov.f32 	%f288, 0f00000000;
	bra.uni 	BB3_46;

BB3_40:
	mov.f32 	%f288, %f27;
	bra.uni 	BB3_46;

BB3_41:
	setp.lt.f32 	%p36, %f158, 0f3F800000;
	mov.b32 	 %r100, %f287;
	setp.lt.s32 	%p6, %r100, 0;
	@%p36 bra 	BB3_43;

	selp.f32 	%f288, 0f00000000, %f27, %p6;
	bra.uni 	BB3_46;

BB3_43:
	selp.f32 	%f288, %f27, 0f00000000, %p6;
	bra.uni 	BB3_46;

BB3_44:
	add.f32 	%f288, %f287, 0f40000000;
	bra.uni 	BB3_46;

BB3_45:
	mov.f32 	%f288, 0f3F800000;

BB3_46:
	mul.f32 	%f267, %f284, %f288;
	cvt.rzi.s32.f32 	%r29, %f267;
	shr.u32 	%r101, %r29, 31;
	add.s32 	%r102, %r29, %r101;
	shr.s32 	%r30, %r102, 1;
	ld.param.u32 	%r141, [DIT2C2C_param_6];
	setp.eq.s32 	%p37, %r141, 1;
	@%p37 bra 	BB3_49;

	ld.param.u32 	%r140, [DIT2C2C_param_6];
	setp.ne.s32 	%p38, %r140, 2;
	@%p38 bra 	BB3_50;

	div.s32 	%r148, %r8, %r30;
	ld.param.u32 	%r138, [DIT2C2C_param_3];
	div.s32 	%r103, %r138, %r29;
	rem.s32 	%r149, %r8, %r30;
	mul.lo.s32 	%r150, %r103, %r149;
	shr.s32 	%r104, %r138, 31;
	shr.u32 	%r105, %r104, 30;
	add.s32 	%r106, %r138, %r105;
	shr.s32 	%r151, %r106, 2;
	ld.param.u32 	%r147, [DIT2C2C_param_2];
	mov.u32 	%r146, %r7;
	bra.uni 	BB3_51;

BB3_49:
	ld.param.u32 	%r137, [DIT2C2C_param_2];
	mul.lo.s32 	%r35, %r8, %r137;
	div.s32 	%r148, %r7, %r30;
	div.s32 	%r108, %r137, %r29;
	rem.s32 	%r149, %r7, %r30;
	mul.lo.s32 	%r150, %r108, %r149;
	shr.s32 	%r109, %r137, 31;
	shr.u32 	%r110, %r109, 30;
	add.s32 	%r111, %r137, %r110;
	shr.s32 	%r151, %r111, 2;
	mov.u32 	%r147, 1;
	mov.u32 	%r146, %r35;
	bra.uni 	BB3_51;

BB3_50:
	mov.u32 	%r151, %r118;
	mov.u32 	%r150, %r119;
	mov.u32 	%r149, %r120;
	mov.u32 	%r148, %r121;
	mov.u32 	%r147, 1;
	mov.u32 	%r146, 0;

BB3_51:
	mad.lo.s32 	%r123, %r148, %r29, %r149;
	mad.lo.s32 	%r124, %r123, %r147, %r146;
	shl.b32 	%r46, %r124, 1;
	mad.lo.s32 	%r125, %r148, %r29, %r30;
	add.s32 	%r126, %r125, %r149;
	mad.lo.s32 	%r127, %r126, %r147, %r146;
	shl.b32 	%r47, %r127, 1;
	rem.s32 	%r128, %r150, %r151;
	shl.b32 	%r129, %r128, 4;
	ld.param.u32 	%r135, [DIT2C2C_param_1];
	add.s32 	%r48, %r135, %r129;
	div.s32 	%r122, %r150, %r151;
	setp.gt.s32 	%p39, %r122, 1;
	@%p39 bra 	BB3_55;

	setp.eq.s32 	%p42, %r122, 0;
	@%p42 bra 	BB3_59;

	setp.eq.s32 	%p43, %r122, 1;
	@%p43 bra 	BB3_54;
	bra.uni 	BB3_60;

BB3_54:
	ld.global.v2.f64 	{%fd45, %fd46}, [%r48];
	neg.f64 	%fd10, %fd45;
	mov.f64 	%fd53, %fd46;
	mov.f64 	%fd54, %fd10;
	bra.uni 	BB3_60;

BB3_55:
	setp.eq.s32 	%p40, %r122, 2;
	@%p40 bra 	BB3_58;

	setp.ne.s32 	%p41, %r122, 3;
	@%p41 bra 	BB3_60;

	ld.global.v2.f64 	{%fd49, %fd50}, [%r48];
	neg.f64 	%fd2, %fd50;
	mov.f64 	%fd53, %fd2;
	mov.f64 	%fd54, %fd49;
	bra.uni 	BB3_60;

BB3_58:
	ld.global.v2.f64 	{%fd47, %fd48}, [%r48];
	neg.f64 	%fd5, %fd47;
	neg.f64 	%fd7, %fd48;
	mov.f64 	%fd53, %fd5;
	mov.f64 	%fd54, %fd7;
	bra.uni 	BB3_60;

BB3_59:
	ld.global.v2.f64 	{%fd53, %fd54}, [%r48];

BB3_60:
	ld.param.u32 	%r139, [DIT2C2C_param_5];
	setp.eq.s32 	%p44, %r139, 0;
	@%p44 bra 	BB3_61;
	bra.uni 	BB3_62;

BB3_61:
	neg.f64 	%fd12, %fd54;
	mov.f64 	%fd53, %fd53;
	mov.f64 	%fd54, %fd12;

BB3_62:
	shl.b32 	%r130, %r46, 3;
	ld.param.u32 	%r134, [DIT2C2C_param_0];
	add.s32 	%r131, %r134, %r130;
	shl.b32 	%r132, %r47, 3;
	add.s32 	%r133, %r134, %r132;
	ld.global.f64 	%fd14, [%r133];
	ld.global.f64 	%fd15, [%r131];
	fma.rn.f64 	%fd16, %fd14, %fd53, %fd15;
	ld.global.f64 	%fd18, [%r133+8];
	neg.f64 	%fd19, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd54, %fd16;
	ld.global.f64 	%fd21, [%r131+8];
	fma.rn.f64 	%fd22, %fd18, %fd53, %fd21;
	fma.rn.f64 	%fd23, %fd14, %fd54, %fd22;
	neg.f64 	%fd24, %fd14;
	fma.rn.f64 	%fd25, %fd24, %fd53, %fd15;
	fma.rn.f64 	%fd26, %fd18, %fd54, %fd25;
	fma.rn.f64 	%fd27, %fd19, %fd53, %fd21;
	fma.rn.f64 	%fd28, %fd24, %fd54, %fd27;
	st.global.f64 	[%r131], %fd20;
	st.global.f64 	[%r131+8], %fd23;
	st.global.f64 	[%r133], %fd26;
	st.global.f64 	[%r133+8], %fd28;
	ret;
}

.entry divide(
	.param .u32 .ptr .global .align 16 divide_param_0,
	.param .u32 divide_param_1,
	.param .u32 divide_param_2
)
{
	.reg .f64 	%fd<13>;
	.reg .s32 	%r<20>;


	ld.param.u32 	%r9, [divide_param_0];
	ld.param.u32 	%r10, [divide_param_1];
	ld.param.u32 	%r11, [divide_param_2];
	// inline asm
	mov.u32 	%r1, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r2, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r3, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r4, %tid.x;
	// inline asm
	// inline asm
	mov.u32 	%r5, %envreg4;
	// inline asm
	// inline asm
	mov.u32 	%r6, %ntid.y;
	// inline asm
	// inline asm
	mov.u32 	%r7, %ctaid.y;
	// inline asm
	// inline asm
	mov.u32 	%r8, %tid.y;
	// inline asm
	add.s32 	%r12, %r8, %r5;
	mad.lo.s32 	%r13, %r7, %r6, %r12;
	mul.lo.s32 	%r14, %r11, %r10;
	cvt.rn.f64.s32 	%fd1, %r14;
	add.s32 	%r15, %r4, %r1;
	mad.lo.s32 	%r16, %r3, %r2, %r15;
	mad.lo.s32 	%r17, %r13, %r10, %r16;
	shl.b32 	%r18, %r17, 4;
	add.s32 	%r19, %r9, %r18;
	ld.global.v2.f64 	{%fd9, %fd10}, [%r19];
	div.rn.f64 	%fd11, %fd9, %fd1;
	div.rn.f64 	%fd12, %fd10, %fd1;
	st.global.v2.f64 	[%r19], {%fd11, %fd12};
	ret;
}

.entry swapkernel(
	.param .u32 .ptr .global .align 8 swapkernel_param_0,
	.param .u32 swapkernel_param_1,
	.param .u32 swapkernel_param_2,
	.param .u32 .ptr .global .align 4 swapkernel_param_3,
	.param .u32 .ptr .global .align 4 swapkernel_param_4,
	.param .u32 swapkernel_param_5
)
{
	.reg .f64 	%fd<9>;
	.reg .pred 	%p<5>;
	.reg .s32 	%r<40>;


	ld.param.u32 	%r1, [swapkernel_param_0];
	ld.param.u32 	%r2, [swapkernel_param_1];
	ld.param.u32 	%r5, [swapkernel_param_5];
	// inline asm
	mov.u32 	%r12, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r13, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r14, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r15, %tid.x;
	// inline asm
	add.s32 	%r20, %r15, %r12;
	mad.lo.s32 	%r6, %r14, %r13, %r20;
	// inline asm
	mov.u32 	%r16, %envreg4;
	// inline asm
	// inline asm
	mov.u32 	%r17, %ntid.y;
	// inline asm
	// inline asm
	mov.u32 	%r18, %ctaid.y;
	// inline asm
	// inline asm
	mov.u32 	%r19, %tid.y;
	// inline asm
	add.s32 	%r21, %r19, %r16;
	mad.lo.s32 	%r7, %r18, %r17, %r21;
	mul.lo.s32 	%r8, %r7, %r2;
	mad.lo.s32 	%r22, %r7, %r2, %r6;
	shl.b32 	%r23, %r22, 4;
	add.s32 	%r9, %r1, %r23;
	setp.eq.s32 	%p1, %r5, 1;
	@%p1 bra 	BB5_4;

	ld.param.u32 	%r39, [swapkernel_param_5];
	setp.ne.s32 	%p2, %r39, 2;
	@%p2 bra 	BB5_6;

	shl.b32 	%r24, %r7, 2;
	ld.param.u32 	%r38, [swapkernel_param_4];
	add.s32 	%r25, %r38, %r24;
	ld.global.u32 	%r10, [%r25];
	setp.ge.s32 	%p3, %r7, %r10;
	@%p3 bra 	BB5_6;

	ld.param.u32 	%r36, [swapkernel_param_1];
	mad.lo.s32 	%r26, %r10, %r36, %r6;
	shl.b32 	%r27, %r26, 4;
	ld.param.u32 	%r35, [swapkernel_param_0];
	add.s32 	%r28, %r35, %r27;
	ld.global.f64 	%fd1, [%r28];
	ld.global.f64 	%fd2, [%r9];
	st.global.f64 	[%r28], %fd2;
	st.global.f64 	[%r9], %fd1;
	ld.global.f64 	%fd3, [%r28+8];
	ld.global.f64 	%fd4, [%r9+8];
	st.global.f64 	[%r28+8], %fd4;
	st.global.f64 	[%r9+8], %fd3;
	ret;

BB5_4:
	shl.b32 	%r29, %r6, 2;
	ld.param.u32 	%r37, [swapkernel_param_3];
	add.s32 	%r30, %r37, %r29;
	ld.global.u32 	%r11, [%r30];
	setp.ge.s32 	%p4, %r6, %r11;
	@%p4 bra 	BB5_6;

	add.s32 	%r31, %r11, %r8;
	shl.b32 	%r32, %r31, 4;
	ld.param.u32 	%r34, [swapkernel_param_0];
	add.s32 	%r33, %r34, %r32;
	ld.global.f64 	%fd5, [%r33];
	ld.global.f64 	%fd6, [%r9];
	st.global.f64 	[%r33], %fd6;
	st.global.f64 	[%r9], %fd5;
	ld.global.f64 	%fd7, [%r33+8];
	ld.global.f64 	%fd8, [%r9+8];
	st.global.f64 	[%r33+8], %fd8;
	st.global.f64 	[%r9+8], %fd7;

BB5_6:
	ret;
}

.entry reverse(
	.param .u32 .ptr .global .align 4 reverse_param_0,
	.param .u32 reverse_param_1
)
{
	.reg .f32 	%f<293>;
	.reg .pred 	%p<40>;
	.reg .s32 	%r<103>;


	ld.param.u32 	%r36, [reverse_param_1];
	// inline asm
	mov.u32 	%r32, %envreg3;
	// inline asm
	// inline asm
	mov.u32 	%r33, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r34, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r35, %tid.x;
	// inline asm
	add.s32 	%r37, %r35, %r32;
	mad.lo.s32 	%r2, %r34, %r33, %r37;
	add.s32 	%r96, %r36, -1;
	setp.gt.s32 	%p7, %r96, -1;
	@%p7 bra 	BB6_2;

	mov.u32 	%r102, 0;
	bra.uni 	BB6_48;

BB6_2:
	mov.f32 	%f1, 0f41300000;
	mov.pred 	%p3, 0;
	mov.f32 	%f46, 0f40000000;
	add.f32 	%f2, %f46, 0f41300000;
	mov.f32 	%f3, 0f7F800000;
	mov.f32 	%f4, 0fFF800000;
	mov.f32 	%f5, 0f00000000;
	mov.f32 	%f6, 0f37000000;
	mov.u32 	%r97, 0;
	mov.u32 	%r102, %r97;

BB6_3:
	and.b32  	%r41, %r96, 31;
	mov.u32 	%r99, 1;
	shl.b32 	%r43, %r99, %r41;
	and.b32  	%r7, %r43, %r2;
	mul.hi.s32 	%r44, %r97, 780903145;
	shr.u32 	%r45, %r44, 31;
	shr.s32 	%r46, %r44, 1;
	add.s32 	%r8, %r46, %r45;
	mul.lo.s32 	%r47, %r8, 11;
	sub.s32 	%r9, %r97, %r47;
	setp.gt.s32 	%p8, %r97, 10;
	@%p8 bra 	BB6_5;

	mov.f32 	%f284, 0f3F800000;
	bra.uni 	BB6_24;

BB6_5:
	mov.u32 	%r98, 0;

BB6_6:
	// inline asm
	abs.f32 	%f48, %f46;
	// inline asm
	selp.f32 	%f283, 0f3F800000, %f2, %p3;
	or.pred  	%p9, %p3, %p3;
	@%p9 bra 	BB6_22;

	mov.f32 	%f54, 0f3F000000;
	mul.rn.f32 	%f51, %f54, %f1;
	// inline asm
	cvt.rmi.f32.f32 	%f50, %f51;
	// inline asm
	mul.rn.f32 	%f56, %f46, %f50;
	sub.f32 	%f57, %f1, %f56;
	setp.eq.f32 	%p10, %f57, 0f3F800000;
	// inline asm
	cvt.rzi.f32.f32 	%f52, %f1;
	// inline asm
	setp.eq.f32 	%p11, %f1, %f52;
	and.pred  	%p4, %p10, %p11;
	setp.eq.f32 	%p12, %f48, 0f00000000;
	@%p12 bra 	BB6_19;

	// inline asm
	abs.f32 	%f58, %f46;
	// inline asm
	mov.b32 	 %r12, %f58;
	shr.u32 	%r50, %r12, 23;
	and.b32  	%r51, %r50, 255;
	add.s32 	%r100, %r51, -127;
	setp.eq.s32 	%p13, %r51, 0;
	mov.f32 	%f280, %f58;
	@%p13 bra 	BB6_9;
	bra.uni 	BB6_10;

BB6_9:
	and.b32  	%r52, %r12, -2139095041;
	or.b32  	%r53, %r52, 1065353216;
	mov.b32 	 %f60, %r53;
	add.f32 	%f61, %f60, 0fBF800000;
	mov.b32 	 %r54, %f61;
	shr.u32 	%r55, %r54, 23;
	and.b32  	%r56, %r55, 255;
	add.s32 	%r100, %r56, -253;
	and.b32  	%r57, %r54, -2139095041;
	or.b32  	%r58, %r57, 1065353216;
	mov.b32 	 %f280, %r58;

BB6_10:
	mov.b32 	 %r59, %f280;
	and.b32  	%r60, %r59, -2139095041;
	or.b32  	%r61, %r60, 1065353216;
	mov.b32 	 %f281, %r61;
	setp.gt.f32 	%p14, %f281, 0f3FB504F3;
	@%p14 bra 	BB6_11;
	bra.uni 	BB6_12;

BB6_11:
	mul.rn.f32 	%f281, %f281, %f54;
	add.s32 	%r100, %r100, 1;

BB6_12:
	add.f32 	%f71, %f281, 0f3F800000;
	rcp.approx.f32 	%f65, %f71;
	add.f32 	%f64, %f281, 0fBF800000;
	// inline asm
	mul.rz.f32 	%f63, %f64, %f65;
	// inline asm
	mul.rn.f32 	%f73, %f46, %f63;
	mul.rn.f32 	%f74, %f73, %f73;
	mov.f32 	%f75, 0f3B18F0FE;
	mul.rn.f32 	%f76, %f75, %f74;
	add.f32 	%f77, %f76, 0f3C4CAF63;
	mul.rn.f32 	%f78, %f77, %f74;
	add.f32 	%f79, %f78, 0f3DAAAABD;
	mul.rn.f32 	%f80, %f79, %f74;
	mul.rn.f32 	%f68, %f80, %f73;
	mov.b32 	 %r62, %f73;
	and.b32  	%r63, %r62, -4096;
	mov.b32 	 %f81, %r63;
	mov.b32 	 %r64, %f64;
	and.b32  	%r65, %r64, -4096;
	mov.b32 	 %f82, %r65;
	sub.f32 	%f83, %f64, %f81;
	mul.rn.f32 	%f84, %f46, %f83;
	sub.f32 	%f85, %f64, %f82;
	mul.rn.f32 	%f86, %f81, %f82;
	sub.f32 	%f87, %f84, %f86;
	mul.rn.f32 	%f88, %f81, %f85;
	sub.f32 	%f89, %f87, %f88;
	mul.rn.f32 	%f90, %f65, %f89;
	add.f32 	%f91, %f81, %f90;
	sub.f32 	%f92, %f91, %f81;
	sub.f32 	%f93, %f90, %f92;
	add.f32 	%f94, %f91, %f68;
	sub.f32 	%f67, %f91, %f94;
	// inline asm
	add.rz.f32 	%f66, %f67, %f68;
	// inline asm
	add.f32 	%f95, %f66, %f93;
	add.f32 	%f96, %f94, %f95;
	sub.f32 	%f97, %f94, %f96;
	add.f32 	%f98, %f97, %f95;
	cvt.rn.f32.s32 	%f99, %r100;
	mov.f32 	%f100, 0f3F317200;
	mul.rn.f32 	%f101, %f99, %f100;
	mov.f32 	%f102, 0f35BFBE8E;
	mul.rn.f32 	%f103, %f99, %f102;
	add.f32 	%f104, %f101, %f96;
	sub.f32 	%f105, %f101, %f104;
	add.f32 	%f106, %f105, %f96;
	add.f32 	%f107, %f106, %f98;
	add.f32 	%f108, %f107, %f103;
	add.f32 	%f15, %f104, %f108;
	sub.f32 	%f109, %f104, %f15;
	add.f32 	%f16, %f109, %f108;
	// inline asm
	abs.f32 	%f69, %f1;
	// inline asm
	setp.gt.f32 	%p15, %f69, 0f77F684DF;
	@%p15 bra 	BB6_14;

	mov.f32 	%f282, %f1;
	bra.uni 	BB6_15;

BB6_14:
	mov.f32 	%f110, 0f39000000;
	mul.rn.f32 	%f17, %f1, %f110;
	mov.f32 	%f282, %f17;

BB6_15:
	mov.f32 	%f18, %f282;
	mov.f32 	%f111, 0f45800800;
	mul.rn.f32 	%f112, %f15, %f111;
	sub.f32 	%f113, %f15, %f112;
	add.f32 	%f114, %f113, %f112;
	sub.f32 	%f115, %f15, %f114;
	mul.rn.f32 	%f116, %f18, %f111;
	sub.f32 	%f117, %f18, %f116;
	add.f32 	%f118, %f117, %f116;
	sub.f32 	%f119, %f18, %f118;
	mul.rn.f32 	%f120, %f114, %f118;
	mul.rn.f32 	%f121, %f15, %f18;
	sub.f32 	%f122, %f120, %f121;
	mul.rn.f32 	%f123, %f114, %f119;
	add.f32 	%f124, %f122, %f123;
	mul.rn.f32 	%f125, %f115, %f118;
	add.f32 	%f126, %f124, %f125;
	mul.rn.f32 	%f127, %f115, %f119;
	add.f32 	%f128, %f126, %f127;
	mul.rn.f32 	%f129, %f16, %f18;
	add.f32 	%f130, %f129, %f128;
	add.f32 	%f131, %f121, %f130;
	sub.f32 	%f132, %f121, %f131;
	add.f32 	%f19, %f132, %f130;
	mov.f32 	%f291, %f19;
	mov.f32 	%f292, %f131;
	mov.b32 	 %r18, %f131;
	setp.eq.s32 	%p16, %r18, 1118925336;
	@%p16 bra 	BB6_16;
	bra.uni 	BB6_17;

BB6_16:
	add.s32 	%r66, %r18, -1;
	mov.b32 	 %f133, %r66;
	add.f32 	%f134, %f19, %f6;
	mov.f32 	%f291, %f134;
	mov.f32 	%f292, %f133;

BB6_17:
	mov.f32 	%f142, 0f3FB8AA3B;
	mul.rn.f32 	%f136, %f292, %f142;
	// inline asm
	cvt.rzi.f32.f32 	%f135, %f136;
	// inline asm
	mul.rn.f32 	%f144, %f135, %f100;
	sub.f32 	%f145, %f292, %f144;
	mul.rn.f32 	%f147, %f135, %f102;
	sub.f32 	%f148, %f145, %f147;
	mul.rn.f32 	%f138, %f148, %f142;
	// inline asm
	ex2.approx.f32 	%f137, %f138;
	// inline asm
	add.f32 	%f140, %f135, 0f00000000;
	// inline asm
	ex2.approx.f32 	%f139, %f140;
	// inline asm
	mul.rn.f32 	%f149, %f137, %f139;
	setp.lt.f32 	%p17, %f292, 0fC2D20000;
	selp.f32 	%f150, 0f00000000, %f149, %p17;
	setp.gt.f32 	%p18, %f292, 0f42D20000;
	selp.f32 	%f283, %f3, %f150, %p18;
	setp.neu.f32 	%p19, %f283, %f3;
	@%p19 bra 	BB6_18;
	bra.uni 	BB6_22;

BB6_18:
	// inline asm
	mad.f32 	%f151, %f283, %f291, %f283;
	// inline asm
	mov.f32 	%f283, %f151;
	bra.uni 	BB6_22;

BB6_19:
	@%p3 bra 	BB6_21;

	selp.f32 	%f283, %f5, 0f00000000, %p4;
	bra.uni 	BB6_22;

BB6_21:
	mov.f32 	%f283, 0f7F800000;

BB6_22:
	cvt.rn.f32.s32 	%f156, %r99;
	mul.f32 	%f157, %f156, %f283;
	cvt.rzi.s32.f32 	%r99, %f157;
	add.s32 	%r98, %r98, 1;
	setp.lt.s32 	%p20, %r98, %r8;
	@%p20 bra 	BB6_6;

	cvt.rn.f32.s32 	%f284, %r99;

BB6_24:
	// inline asm
	abs.f32 	%f158, %f46;
	// inline asm
	cvt.rn.f32.s32 	%f287, %r9;
	setp.eq.f32 	%p21, %f287, 0f00000000;
	@%p21 bra 	BB6_46;

	setp.nan.f32 	%p22, %f287, %f287;
	@%p22 bra 	BB6_45;

	setp.eq.f32 	%p23, %f287, %f3;
	setp.eq.f32 	%p24, %f287, %f4;
	or.pred  	%p25, %p23, %p24;
	@%p25 bra 	BB6_42;

	mov.f32 	%f164, 0f3F000000;
	mul.rn.f32 	%f161, %f164, %f287;
	// inline asm
	cvt.rmi.f32.f32 	%f160, %f161;
	// inline asm
	mul.rn.f32 	%f166, %f46, %f160;
	sub.f32 	%f167, %f287, %f166;
	setp.eq.f32 	%p26, %f167, 0f3F800000;
	// inline asm
	cvt.rzi.f32.f32 	%f162, %f287;
	// inline asm
	setp.eq.f32 	%p27, %f287, %f162;
	and.pred  	%p5, %p26, %p27;
	setp.eq.f32 	%p28, %f158, 0f00000000;
	@%p28 bra 	BB6_39;

	// inline asm
	abs.f32 	%f168, %f46;
	// inline asm
	mov.b32 	 %r21, %f168;
	shr.u32 	%r67, %r21, 23;
	and.b32  	%r68, %r67, 255;
	add.s32 	%r101, %r68, -127;
	setp.eq.s32 	%p29, %r68, 0;
	mov.f32 	%f285, %f168;
	@%p29 bra 	BB6_29;
	bra.uni 	BB6_30;

BB6_29:
	and.b32  	%r69, %r21, -2139095041;
	or.b32  	%r70, %r69, 1065353216;
	mov.b32 	 %f170, %r70;
	add.f32 	%f171, %f170, 0fBF800000;
	mov.b32 	 %r71, %f171;
	shr.u32 	%r72, %r71, 23;
	and.b32  	%r73, %r72, 255;
	add.s32 	%r101, %r73, -253;
	and.b32  	%r74, %r71, -2139095041;
	or.b32  	%r75, %r74, 1065353216;
	mov.b32 	 %f285, %r75;

BB6_30:
	mov.b32 	 %r76, %f285;
	and.b32  	%r77, %r76, -2139095041;
	or.b32  	%r78, %r77, 1065353216;
	mov.b32 	 %f286, %r78;
	setp.gt.f32 	%p30, %f286, 0f3FB504F3;
	@%p30 bra 	BB6_31;
	bra.uni 	BB6_32;

BB6_31:
	mul.rn.f32 	%f286, %f286, %f164;
	add.s32 	%r101, %r101, 1;

BB6_32:
	add.f32 	%f181, %f286, 0f3F800000;
	rcp.approx.f32 	%f175, %f181;
	add.f32 	%f174, %f286, 0fBF800000;
	// inline asm
	mul.rz.f32 	%f173, %f174, %f175;
	// inline asm
	mul.rn.f32 	%f183, %f46, %f173;
	mul.rn.f32 	%f184, %f183, %f183;
	mov.f32 	%f185, 0f3B18F0FE;
	mul.rn.f32 	%f186, %f185, %f184;
	add.f32 	%f187, %f186, 0f3C4CAF63;
	mul.rn.f32 	%f188, %f187, %f184;
	add.f32 	%f189, %f188, 0f3DAAAABD;
	mul.rn.f32 	%f190, %f189, %f184;
	mul.rn.f32 	%f178, %f190, %f183;
	mov.b32 	 %r79, %f183;
	and.b32  	%r80, %r79, -4096;
	mov.b32 	 %f191, %r80;
	mov.b32 	 %r81, %f174;
	and.b32  	%r82, %r81, -4096;
	mov.b32 	 %f192, %r82;
	sub.f32 	%f193, %f174, %f191;
	mul.rn.f32 	%f194, %f46, %f193;
	sub.f32 	%f195, %f174, %f192;
	mul.rn.f32 	%f196, %f191, %f192;
	sub.f32 	%f197, %f194, %f196;
	mul.rn.f32 	%f198, %f191, %f195;
	sub.f32 	%f199, %f197, %f198;
	mul.rn.f32 	%f200, %f175, %f199;
	add.f32 	%f201, %f191, %f200;
	sub.f32 	%f202, %f201, %f191;
	sub.f32 	%f203, %f200, %f202;
	add.f32 	%f204, %f201, %f178;
	sub.f32 	%f177, %f201, %f204;
	// inline asm
	add.rz.f32 	%f176, %f177, %f178;
	// inline asm
	add.f32 	%f205, %f176, %f203;
	add.f32 	%f206, %f204, %f205;
	sub.f32 	%f207, %f204, %f206;
	add.f32 	%f208, %f207, %f205;
	cvt.rn.f32.s32 	%f209, %r101;
	mov.f32 	%f210, 0f3F317200;
	mul.rn.f32 	%f211, %f209, %f210;
	mov.f32 	%f212, 0f35BFBE8E;
	mul.rn.f32 	%f213, %f209, %f212;
	add.f32 	%f214, %f211, %f206;
	sub.f32 	%f215, %f211, %f214;
	add.f32 	%f216, %f215, %f206;
	add.f32 	%f217, %f216, %f208;
	add.f32 	%f218, %f217, %f213;
	add.f32 	%f34, %f214, %f218;
	sub.f32 	%f219, %f214, %f34;
	add.f32 	%f35, %f219, %f218;
	// inline asm
	abs.f32 	%f179, %f287;
	// inline asm
	setp.gt.f32 	%p31, %f179, 0f77F684DF;
	@%p31 bra 	BB6_33;
	bra.uni 	BB6_34;

BB6_33:
	mov.f32 	%f220, 0f39000000;
	mul.rn.f32 	%f287, %f287, %f220;

BB6_34:
	mov.f32 	%f221, 0f45800800;
	mul.rn.f32 	%f222, %f34, %f221;
	sub.f32 	%f223, %f34, %f222;
	add.f32 	%f224, %f223, %f222;
	sub.f32 	%f225, %f34, %f224;
	mul.rn.f32 	%f226, %f287, %f221;
	sub.f32 	%f227, %f287, %f226;
	add.f32 	%f228, %f227, %f226;
	sub.f32 	%f229, %f287, %f228;
	mul.rn.f32 	%f230, %f224, %f228;
	mul.rn.f32 	%f231, %f34, %f287;
	sub.f32 	%f232, %f230, %f231;
	mul.rn.f32 	%f233, %f224, %f229;
	add.f32 	%f234, %f232, %f233;
	mul.rn.f32 	%f235, %f225, %f228;
	add.f32 	%f236, %f234, %f235;
	mul.rn.f32 	%f237, %f225, %f229;
	add.f32 	%f238, %f236, %f237;
	mul.rn.f32 	%f239, %f35, %f287;
	add.f32 	%f240, %f239, %f238;
	add.f32 	%f241, %f231, %f240;
	sub.f32 	%f242, %f231, %f241;
	add.f32 	%f38, %f242, %f240;
	mov.f32 	%f289, %f38;
	mov.f32 	%f290, %f241;
	mov.b32 	 %r27, %f241;
	setp.eq.s32 	%p32, %r27, 1118925336;
	@%p32 bra 	BB6_35;
	bra.uni 	BB6_36;

BB6_35:
	add.s32 	%r83, %r27, -1;
	mov.b32 	 %f243, %r83;
	add.f32 	%f244, %f38, %f6;
	mov.f32 	%f289, %f244;
	mov.f32 	%f290, %f243;

BB6_36:
	mov.f32 	%f252, 0f3FB8AA3B;
	mul.rn.f32 	%f246, %f290, %f252;
	// inline asm
	cvt.rzi.f32.f32 	%f245, %f246;
	// inline asm
	mul.rn.f32 	%f254, %f245, %f210;
	sub.f32 	%f255, %f290, %f254;
	mul.rn.f32 	%f257, %f245, %f212;
	sub.f32 	%f258, %f255, %f257;
	mul.rn.f32 	%f248, %f258, %f252;
	// inline asm
	ex2.approx.f32 	%f247, %f248;
	// inline asm
	add.f32 	%f250, %f245, 0f00000000;
	// inline asm
	ex2.approx.f32 	%f249, %f250;
	// inline asm
	mul.rn.f32 	%f259, %f247, %f249;
	setp.lt.f32 	%p33, %f290, 0fC2D20000;
	selp.f32 	%f260, 0f00000000, %f259, %p33;
	setp.gt.f32 	%p34, %f290, 0f42D20000;
	selp.f32 	%f39, %f3, %f260, %p34;
	setp.neu.f32 	%p35, %f39, %f3;
	@%p35 bra 	BB6_38;

	mov.f32 	%f288, %f39;
	bra.uni 	BB6_47;

BB6_38:
	// inline asm
	mad.f32 	%f261, %f39, %f289, %f39;
	// inline asm
	mov.f32 	%f40, %f261;
	mov.f32 	%f288, %f40;
	bra.uni 	BB6_47;

BB6_39:
	setp.lt.f32 	%p36, %f287, 0f00000000;
	@%p36 bra 	BB6_41;

	selp.f32 	%f41, %f5, 0f00000000, %p5;
	mov.f32 	%f288, %f41;
	bra.uni 	BB6_47;

BB6_41:
	mov.f32 	%f288, %f3;
	bra.uni 	BB6_47;

BB6_42:
	setp.lt.f32 	%p37, %f158, 0f3F800000;
	mov.b32 	 %r84, %f287;
	setp.lt.s32 	%p6, %r84, 0;
	@%p37 bra 	BB6_44;

	selp.f32 	%f42, 0f00000000, %f3, %p6;
	mov.f32 	%f288, %f42;
	bra.uni 	BB6_47;

BB6_44:
	selp.f32 	%f43, %f3, 0f00000000, %p6;
	mov.f32 	%f288, %f43;
	bra.uni 	BB6_47;

BB6_45:
	add.f32 	%f44, %f287, 0f40000000;
	mov.f32 	%f288, %f44;
	bra.uni 	BB6_47;

BB6_46:
	mov.f32 	%f266, 0f3F800000;
	mov.f32 	%f288, %f266;

BB6_47:
	mov.f32 	%f45, %f288;
	mul.f32 	%f267, %f284, %f45;
	cvt.rzi.s32.f32 	%r85, %f267;
	setp.eq.s32 	%p38, %r7, 0;
	selp.b32 	%r86, 0, %r85, %p38;
	add.s32 	%r102, %r86, %r102;
	add.s32 	%r97, %r97, 1;
	add.s32 	%r96, %r96, -1;
	setp.gt.s32 	%p39, %r96, -1;
	@%p39 bra 	BB6_3;

BB6_48:
	shl.b32 	%r89, %r2, 2;
	ld.param.u32 	%r95, [reverse_param_0];
	add.s32 	%r90, %r95, %r89;
	st.global.u32 	[%r90], %r102;
	// inline asm
	mov.u32 	%r87, %envreg6;
	// inline asm
	// inline asm
	mov.u32 	%r88, %ntid.x;
	// inline asm
	mad.lo.s32 	%r91, %r88, %r87, %r2;
	shl.b32 	%r92, %r91, 2;
	add.s32 	%r93, %r95, %r92;
	add.s32 	%r94, %r102, 1;
	st.global.u32 	[%r93], %r94;
	ret;
}


$
